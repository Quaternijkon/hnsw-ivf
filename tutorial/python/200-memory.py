import numpy as np
import faiss
import time
import os
import platform
import resource
import struct
import re
import psutil
import tracemalloc
import gc
from contextlib import contextmanager
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.patches import Rectangle
import numpy as np

# ==============================================================================
# 0. è·¯å¾„å’Œæ–‡ä»¶åé…ç½® & è°ƒè¯•å¼€å…³
# ==============================================================================
DATA_DIR = "./sift"
LEARN_FILE = os.path.join(DATA_DIR, "learn.fbin")
BASE_FILE = os.path.join(DATA_DIR, "base.fbin")
QUERY_FILE = os.path.join(DATA_DIR, "query.fbin")
GROUNDTRUTH_FILE = os.path.join(DATA_DIR, "groundtruth.ivecs")

# è°ƒè¯•å¼€å…³
ENABLE_IVF_STATS = False  # æ§åˆ¶æ˜¯å¦è¾“å‡ºIVFåˆ†åŒºç»Ÿè®¡ä¿¡æ¯

# æ–°å¢å¼€å…³ - æ§åˆ¶æ˜¯å¦ç»Ÿè®¡æœç´¢åˆ†åŒºä¿¡æ¯
ENABLE_SEARCH_PARTITION_STATS = False
SEARCH_STATS_FILENAME = os.path.join(DATA_DIR, "search_partition_ratios.txt")

# å†…å­˜ç›‘æ§å¼€å…³
ENABLE_DETAILED_MEMORY_MONITORING = True
MEMORY_LOG_FILENAME = os.path.join(DATA_DIR, "memory_usage_log.txt")

# å†…å­˜ä¼˜åŒ–é…ç½®
MEMORY_OPTIMIZATION_CONFIG = {
    'enable_gc_before_search': True,  # æœç´¢å‰è¿›è¡Œåƒåœ¾å›æ”¶
    'enable_gc_after_search': True,  # æœç´¢åè¿›è¡Œåƒåœ¾å›æ”¶
    'gc_threshold_mb': 100,  # å†…å­˜å¢é•¿è¶…è¿‡æ­¤å€¼æ—¶è§¦å‘GC
    'max_memory_mb': 1000,  # æœ€å¤§å†…å­˜ä½¿ç”¨é™åˆ¶
    'enable_memory_compression': False,  # å¯ç”¨å†…å­˜å‹ç¼©ï¼ˆå®éªŒæ€§ï¼‰
    'chunk_size_optimization': True,  # å¯ç”¨åˆ†å—å¤§å°ä¼˜åŒ–
}

# å†…å­˜å¯è§†åŒ–é…ç½®
ENABLE_MEMORY_VISUALIZATION = True
MEMORY_PLOT_FILENAME = os.path.join(DATA_DIR, "memory_usage_plot.png")

# è¿è¡Œç»“æŸæ—¶å†…å­˜å›¾è¡¨é…ç½®
ENABLE_FINAL_MEMORY_PLOT = True  # æ§åˆ¶æ˜¯å¦åœ¨è¿è¡Œç»“æŸæ—¶ç”Ÿæˆå†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨
FINAL_MEMORY_PLOT_FILENAME = os.path.join(DATA_DIR, "final_memory_usage_plot.png")


# ==============================================================================
# 1. é«˜çº§å†…å­˜ç›‘æ§ç±»
# ==============================================================================
class AdvancedMemoryMonitor:
    """é«˜çº§å†…å­˜ç›‘æ§ç±»ï¼Œæä¾›å¤šç§å†…å­˜ç›‘æ§åŠŸèƒ½"""

    def __init__(self, enable_tracemalloc: bool = True, log_file: Optional[str] = None):
        self.enable_tracemalloc = enable_tracemalloc
        self.log_file = log_file
        self.memory_snapshots: List[Dict] = []
        self.process = psutil.Process()
        self.index_memory_baseline = None  # ç´¢å¼•åŠ è½½åçš„å†…å­˜åŸºçº¿
        self.search_memory_breakdown = []  # æœç´¢æœŸé—´å†…å­˜åˆ†è§£

        if self.enable_tracemalloc:
            tracemalloc.start()

        if self.log_file:
            with open(self.log_file, 'w') as f:
                f.write("æ—¶é—´æˆ³,é˜¶æ®µ,RSS_MB,VMS_MB,å†…å­˜ç™¾åˆ†æ¯”,Pythonå¯¹è±¡æ•°,åƒåœ¾å›æ”¶æ¬¡æ•°,ç´¢å¼•å†…å­˜_MB,å…¶ä»–å†…å­˜_MB\n")

    def get_memory_info(self) -> Dict:
        """è·å–è¯¦ç»†çš„å†…å­˜ä¿¡æ¯"""
        memory_info = self.process.memory_info()
        memory_percent = self.process.memory_percent()

        # è·å–Pythonå¯¹è±¡ç»Ÿè®¡
        gc_stats = gc.get_stats()
        total_objects = sum(stat['collected'] for stat in gc_stats)

        info = {
            'timestamp': time.time(),
            'rss_mb': memory_info.rss / (1024 * 1024),  # å®é™…ç‰©ç†å†…å­˜
            'vms_mb': memory_info.vms / (1024 * 1024),  # è™šæ‹Ÿå†…å­˜
            'memory_percent': memory_percent,
            'python_objects': len(gc.get_objects()),
            'gc_collections': total_objects
        }

        # å¦‚æœå¯ç”¨äº†tracemallocï¼Œæ·»åŠ æ›´è¯¦ç»†çš„ä¿¡æ¯
        if self.enable_tracemalloc and tracemalloc.is_tracing():
            current, peak = tracemalloc.get_traced_memory()
            info.update({
                'traced_current_mb': current / (1024 * 1024),
                'traced_peak_mb': peak / (1024 * 1024)
            })

        # è®¡ç®—ç´¢å¼•å†…å­˜å’Œå…¶ä»–å†…å­˜çš„åˆ†è§£
        if self.index_memory_baseline is not None:
            index_memory = self.estimate_index_memory()
            other_memory = info['rss_mb'] - index_memory
            info.update({
                'index_memory_mb': index_memory,
                'other_memory_mb': other_memory
            })
        else:
            info.update({
                'index_memory_mb': 0,
                'other_memory_mb': info['rss_mb']
            })

        return info

    def estimate_index_memory(self) -> float:
        """ä¼°ç®—ç´¢å¼•å ç”¨çš„å†…å­˜"""
        if self.index_memory_baseline is None:
            return 0

        # åŸºäºç´¢å¼•å¤§å°ä¼°ç®—å†…å­˜ä½¿ç”¨
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„ä¼°ç®—ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è®¡ç®—
        current_rss = self.process.memory_info().rss / (1024 * 1024)
        return min(current_rss - self.index_memory_baseline, current_rss * 0.8)

    def set_index_memory_baseline(self, baseline_mb: float):
        """è®¾ç½®ç´¢å¼•å†…å­˜åŸºçº¿"""
        self.index_memory_baseline = baseline_mb
        print(f"[å†…å­˜ç›‘æ§] è®¾ç½®ç´¢å¼•å†…å­˜åŸºçº¿: {baseline_mb:.2f} MB")

    def analyze_memory_growth_pattern(self) -> Dict:
        """åˆ†æå†…å­˜å¢é•¿æ¨¡å¼"""
        if len(self.memory_snapshots) < 2:
            return {}

        analysis = {
            'total_growth_mb': 0,
            'growth_phases': [],
            'peak_usage_mb': 0,
            'memory_efficiency': 0
        }

        # è®¡ç®—æ€»å¢é•¿
        first_snapshot = self.memory_snapshots[0]
        last_snapshot = self.memory_snapshots[-1]
        analysis['total_growth_mb'] = last_snapshot['rss_mb'] - first_snapshot['rss_mb']
        analysis['peak_usage_mb'] = max(s['rss_mb'] for s in self.memory_snapshots)

        # åˆ†æå„é˜¶æ®µå¢é•¿
        for i in range(1, len(self.memory_snapshots)):
            prev = self.memory_snapshots[i - 1]
            curr = self.memory_snapshots[i]
            growth = curr['rss_mb'] - prev['rss_mb']
            analysis['growth_phases'].append({
                'phase': curr.get('phase', f'é˜¶æ®µ{i}'),
                'growth_mb': growth,
                'rss_mb': curr['rss_mb']
            })

        return analysis

    def log_memory_snapshot(self, phase: str):
        """è®°å½•å†…å­˜å¿«ç…§"""
        info = self.get_memory_info()
        info['phase'] = phase
        self.memory_snapshots.append(info)

        if self.log_file:
            with open(self.log_file, 'a') as f:
                f.write(f"{info['timestamp']:.2f},{phase},{info['rss_mb']:.2f},"
                        f"{info['vms_mb']:.2f},{info['memory_percent']:.2f},"
                        f"{info['python_objects']},{info['gc_collections']},"
                        f"{info['index_memory_mb']:.2f},{info['other_memory_mb']:.2f}\n")

        print(f"[å†…å­˜ç›‘æ§] {phase}: RSS={info['rss_mb']:.2f}MB, "
              f"VMS={info['vms_mb']:.2f}MB, å¯¹è±¡æ•°={info['python_objects']}, "
              f"ç´¢å¼•å†…å­˜={info['index_memory_mb']:.2f}MB, å…¶ä»–å†…å­˜={info['other_memory_mb']:.2f}MB")

    @contextmanager
    def monitor_phase(self, phase_name: str):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºç›‘æ§ç‰¹å®šä»£ç æ®µçš„å†…å­˜ä½¿ç”¨"""
        print(f"\n[å†…å­˜ç›‘æ§] å¼€å§‹é˜¶æ®µ: {phase_name}")
        self.log_memory_snapshot(f"{phase_name}_å¼€å§‹")

        start_info = self.get_memory_info()
        start_time = time.time()

        try:
            yield
        finally:
            end_time = time.time()
            end_info = self.get_memory_info()

            # è®¡ç®—å†…å­˜å˜åŒ–
            rss_diff = end_info['rss_mb'] - start_info['rss_mb']
            vms_diff = end_info['vms_mb'] - start_info['vms_mb']
            objects_diff = end_info['python_objects'] - start_info['python_objects']

            print(f"[å†…å­˜ç›‘æ§] ç»“æŸé˜¶æ®µ: {phase_name}")
            print(f"  è€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"  RSSå˜åŒ–: {rss_diff:+.2f}MB")
            print(f"  VMSå˜åŒ–: {vms_diff:+.2f}MB")
            print(f"  Pythonå¯¹è±¡å˜åŒ–: {objects_diff:+d}")

            self.log_memory_snapshot(f"{phase_name}_ç»“æŸ")

    def get_memory_summary(self) -> Dict:
        """è·å–å†…å­˜ä½¿ç”¨æ‘˜è¦"""
        if not self.memory_snapshots:
            return {}

        rss_values = [s['rss_mb'] for s in self.memory_snapshots]
        vms_values = [s['vms_mb'] for s in self.memory_snapshots]

        return {
            'peak_rss_mb': max(rss_values),
            'peak_vms_mb': max(vms_values),
            'avg_rss_mb': sum(rss_values) / len(rss_values),
            'avg_vms_mb': sum(vms_values) / len(vms_values),
            'total_snapshots': len(self.memory_snapshots)
        }

    def force_gc_and_log(self, phase: str):
        """å¼ºåˆ¶åƒåœ¾å›æ”¶å¹¶è®°å½•å†…å­˜å˜åŒ–"""
        before_info = self.get_memory_info()
        gc.collect()
        after_info = self.get_memory_info()

        rss_freed = before_info['rss_mb'] - after_info['rss_mb']
        objects_freed = before_info['python_objects'] - after_info['python_objects']

        print(f"[åƒåœ¾å›æ”¶] {phase}: é‡Šæ”¾RSS={rss_freed:.2f}MB, å¯¹è±¡={objects_freed}")
        self.log_memory_snapshot(f"{phase}_GCå")

    def get_tracemalloc_top_stats(self, limit: int = 10):
        """è·å–tracemallocç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        if not self.enable_tracemalloc or not tracemalloc.is_tracing():
            return None

        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')

        print(f"\n[å†…å­˜åˆ†æ] Top {limit} å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ:")
        for index, stat in enumerate(top_stats[:limit], 1):
            print(f"{index}. {stat}")

        return top_stats[:limit]

    def get_memory_optimization_suggestions(self) -> List[str]:
        """è·å–å†…å­˜ä¼˜åŒ–å»ºè®®"""
        suggestions = []

        if not self.memory_snapshots:
            return suggestions

        # åˆ†æå†…å­˜å¢é•¿æ¨¡å¼
        analysis = self.analyze_memory_growth_pattern()

        if analysis.get('total_growth_mb', 0) > 500:  # å¦‚æœæ€»å¢é•¿è¶…è¿‡500MB
            suggestions.append("âš ï¸  å†…å­˜å¢é•¿è¾ƒå¤§ï¼Œå»ºè®®åœ¨æœç´¢å‰è¿›è¡Œåƒåœ¾å›æ”¶")

        # æ£€æŸ¥VMS/RSSæ¯”ä¾‹
        last_snapshot = self.memory_snapshots[-1]
        vms_rss_ratio = last_snapshot['vms_mb'] / last_snapshot['rss_mb']
        if vms_rss_ratio > 10:  # VMSæ¯”RSSå¤§10å€ä»¥ä¸Š
            suggestions.append("âš ï¸  VMS/RSSæ¯”ä¾‹è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜ç¢ç‰‡åŒ–")

        # æ£€æŸ¥Pythonå¯¹è±¡æ•°é‡
        if last_snapshot['python_objects'] > 100000:
            suggestions.append("âš ï¸  Pythonå¯¹è±¡æ•°é‡è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰å¯¹è±¡æ³„æ¼")

        # æ£€æŸ¥ç´¢å¼•å†…å­˜å æ¯”
        if last_snapshot.get('index_memory_mb', 0) > 0:
            index_ratio = last_snapshot['index_memory_mb'] / last_snapshot['rss_mb']
            if index_ratio < 0.3:  # ç´¢å¼•å†…å­˜å æ¯”å°äº30%
                suggestions.append("ğŸ’¡ ç´¢å¼•å†…å­˜å æ¯”è¾ƒä½ï¼Œå…¶ä»–å†…å­˜ä½¿ç”¨å¯èƒ½è¿‡å¤š")
            elif index_ratio > 0.8:  # ç´¢å¼•å†…å­˜å æ¯”å¤§äº80%
                suggestions.append("ğŸ’¡ ç´¢å¼•å†…å­˜å æ¯”å¾ˆé«˜ï¼Œè¿™æ˜¯æ­£å¸¸çš„")

        return suggestions

    def generate_final_memory_plot(self, plot_filename: str):
        """ç”Ÿæˆæœ€ç»ˆçš„å†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨ï¼ˆä»…RSSå†…å­˜ï¼ŒæŒ‰é˜¶æ®µåˆ†å¸ƒï¼‰"""
        if not self.memory_snapshots or len(self.memory_snapshots) < 2:
            print("å†…å­˜å¿«ç…§æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆæœ€ç»ˆå†…å­˜å›¾è¡¨")
            return

        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'SimHei', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False

        # åˆ›å»ºå•ä¸ªå›¾è¡¨ï¼Œä¸“æ³¨äºRSSå†…å­˜ä½¿ç”¨
        fig, ax = plt.subplots(1, 1, figsize=(16, 10))
        fig.suptitle('Faissç¨‹åºè¿è¡Œå†…å­˜ä½¿ç”¨æƒ…å†µåˆ†æ', fontsize=18, fontweight='bold')

        # å‡†å¤‡æ•°æ®
        timestamps = [s['timestamp'] for s in self.memory_snapshots]
        phases = [s.get('phase', 'Unknown') for s in self.memory_snapshots]
        rss_values = [s['rss_mb'] for s in self.memory_snapshots]
        index_memory = [s.get('index_memory_mb', 0) for s in self.memory_snapshots]
        other_memory = [s.get('other_memory_mb', 0) for s in self.memory_snapshots]

        # è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
        start_time = timestamps[0]
        relative_times = [(t - start_time) for t in timestamps]

        # è¯†åˆ«ä¸»è¦é˜¶æ®µ
        phase_boundaries = self._identify_main_phases(phases, relative_times)
        
        # ç»˜åˆ¶RSSå†…å­˜æ›²çº¿
        ax.plot(relative_times, rss_values, 'b-', linewidth=3, label='RSSç‰©ç†å†…å­˜', marker='o', markersize=6)
        ax.fill_between(relative_times, rss_values, alpha=0.3, color='blue')

        # ç»˜åˆ¶å†…å­˜åˆ†è§£çš„å †å åŒºåŸŸå›¾
        ax.fill_between(relative_times, 0, index_memory, alpha=0.6, color='green', label='ç´¢å¼•å†…å­˜')
        ax.fill_between(relative_times, index_memory, [idx + other for idx, other in zip(index_memory, other_memory)], 
                       alpha=0.6, color='orange', label='å…¶ä»–å†…å­˜')

        # æ·»åŠ é˜¶æ®µåˆ†éš”çº¿å’Œé¢œè‰²èƒŒæ™¯
        self._add_phase_backgrounds(ax, phase_boundaries, relative_times, max(rss_values))
        
        # æ·»åŠ å†…å­˜å¢é•¿ç‚¹æ ‡æ³¨
        self._add_memory_growth_annotations(ax, relative_times, rss_values, phases)

        # è®¾ç½®å›¾è¡¨å±æ€§
        ax.set_xlabel('è¿è¡Œæ—¶é—´ (ç§’)', fontsize=14)
        ax.set_ylabel('å†…å­˜ä½¿ç”¨é‡ (MB)', fontsize=14)
        ax.set_title('å†…å­˜ä½¿ç”¨æ—¶é—´çº¿ - æŒ‰è¿è¡Œé˜¶æ®µåˆ†æ', fontsize=16, fontweight='bold')
        ax.legend(fontsize=12, loc='upper left')
        ax.grid(True, alpha=0.3)

        # æ·»åŠ è¯¦ç»†çš„å†…å­˜åˆ†ææ–‡æœ¬æ¡†
        self._add_detailed_memory_analysis(fig, rss_values, index_memory, other_memory, phase_boundaries, relative_times)

        plt.tight_layout()
        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
        print(f"æœ€ç»ˆå†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨å·²ä¿å­˜åˆ°: {plot_filename}")
        plt.close()

    def _identify_main_phases(self, phases, relative_times):
        """è¯†åˆ«ä¸»è¦çš„è¿è¡Œé˜¶æ®µï¼ˆè®­ç»ƒã€æ„å»ºã€æœç´¢ï¼‰"""
        boundaries = []
        current_phase = None
        
        for i, phase in enumerate(phases):
            phase_lower = phase.lower()
            
            # è®­ç»ƒé˜¶æ®µ
            if ('è®­ç»ƒ' in phase or 'train' in phase_lower or 'é‡åŒ–å™¨' in phase) and current_phase != 'training':
                boundaries.append(('training', i, relative_times[i] if i < len(relative_times) else 0, 'è®­ç»ƒé˜¶æ®µ'))
                current_phase = 'training'
            
            # æ„å»ºé˜¶æ®µï¼ˆåŒ…æ‹¬æ·»åŠ æ•°æ®ï¼‰
            elif ('æ„å»º' in phase or 'æ·»åŠ ' in phase or 'build' in phase_lower or 'add' in phase_lower) and current_phase != 'building':
                boundaries.append(('building', i, relative_times[i] if i < len(relative_times) else 0, 'æ„å»ºé˜¶æ®µ'))
                current_phase = 'building'
            
            # æœç´¢é˜¶æ®µ
            elif ('æœç´¢' in phase or 'search' in phase_lower or 'æŸ¥è¯¢' in phase) and current_phase != 'searching':
                boundaries.append(('searching', i, relative_times[i] if i < len(relative_times) else 0, 'æœç´¢é˜¶æ®µ'))
                current_phase = 'searching'
                
            # è¯„ä¼°é˜¶æ®µ
            elif ('å¬å›' in phase or 'è®¡ç®—' in phase or 'recall' in phase_lower or 'evaluation' in phase_lower) and current_phase != 'evaluation':
                boundaries.append(('evaluation', i, relative_times[i] if i < len(relative_times) else 0, 'è¯„ä¼°é˜¶æ®µ'))
                current_phase = 'evaluation'
        
        return boundaries

    def _add_phase_backgrounds(self, ax, phase_boundaries, relative_times, max_value):
        """æ·»åŠ é˜¶æ®µèƒŒæ™¯è‰²å’Œåˆ†éš”çº¿"""
        if not phase_boundaries:
            return
            
        # å®šä¹‰é˜¶æ®µé¢œè‰²
        phase_colors = {
            'training': 'lightblue',
            'building': 'lightgreen', 
            'searching': 'lightyellow',
            'evaluation': 'lightcoral'
        }
        
        # æ·»åŠ èƒŒæ™¯è‰²
        for i, (phase_type, idx, time_point, label) in enumerate(phase_boundaries):
            # è®¡ç®—é˜¶æ®µçš„æ—¶é—´èŒƒå›´
            start_time = time_point
            if i + 1 < len(phase_boundaries):
                end_time = phase_boundaries[i + 1][2]
            else:
                end_time = relative_times[-1] if relative_times else start_time + 1
                
            # æ·»åŠ èƒŒæ™¯è‰²
            ax.axvspan(start_time, end_time, alpha=0.2, color=phase_colors.get(phase_type, 'lightgray'))
            
            # æ·»åŠ åˆ†éš”çº¿
            ax.axvline(x=start_time, color='red', linestyle='--', alpha=0.8, linewidth=2)
            
            # æ·»åŠ é˜¶æ®µæ ‡ç­¾
            label_x = start_time + (end_time - start_time) / 2
            ax.text(label_x, max_value * 0.95, label, ha='center', va='top', 
                   fontsize=12, fontweight='bold', 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor=phase_colors.get(phase_type, 'lightgray'), alpha=0.8))

    def _add_memory_growth_annotations(self, ax, relative_times, rss_values, phases):
        """æ·»åŠ å†…å­˜å¢é•¿å…³é”®ç‚¹çš„æ ‡æ³¨"""
        if len(rss_values) < 2:
            return
            
        # æ‰¾åˆ°å†…å­˜æ˜¾è‘—å¢é•¿çš„ç‚¹
        growth_points = []
        for i in range(1, len(rss_values)):
            growth = rss_values[i] - rss_values[i-1]
            if growth > 50:  # å¢é•¿è¶…è¿‡50MBçš„ç‚¹
                growth_points.append((i, growth, relative_times[i], rss_values[i], phases[i]))
        
        # æ ‡æ³¨æ˜¾è‘—å¢é•¿ç‚¹
        for idx, growth, time_point, memory_value, phase in growth_points[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªç‚¹
            ax.annotate(f'+{growth:.0f}MB\n{phase}', 
                       xy=(time_point, memory_value), 
                       xytext=(time_point + max(relative_times) * 0.05, memory_value + max(rss_values) * 0.05),
                       arrowprops=dict(arrowstyle='->', color='red', lw=1.5),
                       fontsize=10, ha='left', va='bottom',
                       bbox=dict(boxstyle="round,pad=0.2", facecolor="yellow", alpha=0.7))

    def _add_detailed_memory_analysis(self, fig, rss_values, index_memory, other_memory, phase_boundaries, relative_times):
        """æ·»åŠ è¯¦ç»†çš„å†…å­˜åˆ†æä¿¡æ¯"""
        if not rss_values:
            return
            
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        peak_rss = max(rss_values)
        final_rss = rss_values[-1]
        total_growth = final_rss - rss_values[0]
        final_index_memory = index_memory[-1] if index_memory else 0
        final_other_memory = other_memory[-1] if other_memory else 0
        
        # è®¡ç®—å„é˜¶æ®µçš„å†…å­˜ä½¿ç”¨
        phase_memory_info = []
        for i, (phase_type, idx, time_point, label) in enumerate(phase_boundaries):
            if idx < len(rss_values):
                phase_memory = rss_values[idx]
                phase_memory_info.append(f"{label}: {phase_memory:.1f}MB")
        
        # åˆ›å»ºåˆ†ææ–‡æœ¬
        analysis_text = f"""å†…å­˜ä½¿ç”¨è¯¦ç»†åˆ†æ:

å³°å€¼å†…å­˜: {peak_rss:.1f} MB
æ€»å†…å­˜å¢é•¿: {total_growth:.1f} MB
æœ€ç»ˆå†…å­˜: {final_rss:.1f} MB

å†…å­˜æ„æˆ:
â€¢ ç´¢å¼•å†…å­˜: {final_index_memory:.1f} MB ({final_index_memory/final_rss*100:.1f}%)
â€¢ å…¶ä»–å†…å­˜: {final_other_memory:.1f} MB ({final_other_memory/final_rss*100:.1f}%)

å„é˜¶æ®µå†…å­˜:
{chr(10).join(phase_memory_info)}

å†…å­˜æ•ˆç‡åˆ†æ:
â€¢ å†…å­˜åˆ©ç”¨ç‡: {'è‰¯å¥½' if final_index_memory/final_rss > 0.5 else 'å¯ä¼˜åŒ–'}
â€¢ å†…å­˜å¢é•¿: {'å¹³ç¨³' if total_growth < peak_rss * 0.5 else 'è¾ƒå¤§'}"""

        # æ·»åŠ åˆ†ææ–‡æœ¬æ¡†
        fig.text(0.02, 0.02, analysis_text, fontsize=11,
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.9),
                verticalalignment='bottom', horizontalalignment='left')

    def generate_memory_visualization(self, plot_filename: str):
        """ç”Ÿæˆå†…å­˜ä½¿ç”¨æƒ…å†µå¯è§†åŒ–å›¾è¡¨"""
        if not self.memory_snapshots or len(self.memory_snapshots) < 2:
            print("å†…å­˜å¿«ç…§æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
            return

        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'SimHei', 'sans-serif'] # ä½¿ç”¨æ–°å®‰è£…çš„å­—ä½“
        plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))
        fig.suptitle('Faisså†…å­˜ä½¿ç”¨æƒ…å†µåˆ†æ', fontsize=16, fontweight='bold')

        # å‡†å¤‡æ•°æ®``
        timestamps = [s['timestamp'] for s in self.memory_snapshots]
        phases = [s.get('phase', 'Unknown') for s in self.memory_snapshots]
        rss_values = [s['rss_mb'] for s in self.memory_snapshots]
        vms_values = [s['vms_mb'] for s in self.memory_snapshots]
        index_memory = [s.get('index_memory_mb', 0) for s in self.memory_snapshots]
        other_memory = [s.get('other_memory_mb', 0) for s in self.memory_snapshots]
        python_objects = [s['python_objects'] for s in self.memory_snapshots]

        # è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
        start_time = timestamps[0]
        relative_times = [(t - start_time) for t in timestamps]

        # è¯†åˆ«é˜¶æ®µ
        phase_boundaries = self._identify_phase_boundaries(phases)

        # å­å›¾1: å†…å­˜ä½¿ç”¨è¶‹åŠ¿
        ax1.plot(relative_times, rss_values, 'b-', linewidth=2, label='RSSå†…å­˜', marker='o', markersize=4)
        ax1.plot(relative_times, vms_values, 'r--', linewidth=2, label='VMSå†…å­˜', marker='s', markersize=4)
        ax1.fill_between(relative_times, rss_values, alpha=0.3, color='blue')
        ax1.fill_between(relative_times, vms_values, alpha=0.1, color='red')

        # æ·»åŠ é˜¶æ®µåˆ†å‰²çº¿
        self._add_phase_boundaries(ax1, phase_boundaries, relative_times, rss_values)

        ax1.set_ylabel('å†…å­˜ä½¿ç”¨ (MB)', fontsize=12)
        ax1.set_title('å†…å­˜ä½¿ç”¨è¶‹åŠ¿', fontsize=14, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # å­å›¾2: å†…å­˜åˆ†è§£åˆ†æ
        ax2.bar(relative_times, index_memory, width=0.1, label='ç´¢å¼•å†…å­˜', color='green', alpha=0.7)
        ax2.bar(relative_times, other_memory, width=0.1, bottom=index_memory, label='å…¶ä»–å†…å­˜', color='orange', alpha=0.7)

        # æ·»åŠ é˜¶æ®µåˆ†å‰²çº¿
        self._add_phase_boundaries(ax2, phase_boundaries, relative_times, rss_values)

        ax2.set_ylabel('å†…å­˜åˆ†è§£ (MB)', fontsize=12)
        ax2.set_title('å†…å­˜ä½¿ç”¨åˆ†è§£åˆ†æ', fontsize=14, fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # å­å›¾3: Pythonå¯¹è±¡æ•°é‡
        ax3.plot(relative_times, python_objects, 'g-', linewidth=2, label='Pythonå¯¹è±¡æ•°', marker='^', markersize=4)
        ax3.fill_between(relative_times, python_objects, alpha=0.3, color='green')

        # æ·»åŠ é˜¶æ®µåˆ†å‰²çº¿
        self._add_phase_boundaries(ax3, phase_boundaries, relative_times, python_objects)

        ax3.set_xlabel('è¿è¡Œæ—¶é—´ (ç§’)', fontsize=12)
        ax3.set_ylabel('Pythonå¯¹è±¡æ•°é‡', fontsize=12)
        ax3.set_title('Pythonå¯¹è±¡æ•°é‡å˜åŒ–', fontsize=14, fontweight='bold')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # æ·»åŠ é˜¶æ®µæ ‡ç­¾
        self._add_phase_labels(fig, phase_boundaries, relative_times)

        # æ·»åŠ å†…å­˜åˆ†ææ³¨é‡Š
        self._add_memory_analysis_annotations(fig, rss_values, vms_values, index_memory, other_memory)

        plt.tight_layout()
        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
        print(f"å†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨å·²ä¿å­˜åˆ°: {plot_filename}")
        plt.close()

    def _identify_phase_boundaries(self, phases):
        """è¯†åˆ«é˜¶æ®µè¾¹ç•Œ"""
        boundaries = []
        current_phase = None

        for i, phase in enumerate(phases):
            if 'è®­ç»ƒ' in phase or 'æ„å»º' in phase:
                if current_phase != 'training':
                    boundaries.append(('training', i, 'è®­ç»ƒ/æ„å»ºé˜¶æ®µ'))
                    current_phase = 'training'
            elif 'æœç´¢' in phase:
                if current_phase != 'search':
                    boundaries.append(('search', i, 'æœç´¢é˜¶æ®µ'))
                    current_phase = 'search'
            elif 'å¬å›ç‡' in phase or 'è®¡ç®—' in phase:
                if current_phase != 'evaluation':
                    boundaries.append(('evaluation', i, 'è¯„ä¼°é˜¶æ®µ'))
                    current_phase = 'evaluation'

        return boundaries

    def _add_phase_boundaries(self, ax, phase_boundaries, relative_times, values):
        """æ·»åŠ é˜¶æ®µåˆ†å‰²çº¿"""
        for phase_type, idx, label in phase_boundaries:
            if idx < len(relative_times):
                x_pos = relative_times[idx]
                y_max = max(values) if values else 0
                ax.axvline(x=x_pos, color='red', linestyle='--', alpha=0.7, linewidth=2)
                ax.text(x_pos, y_max * 0.9, label, rotation=90,
                        verticalalignment='top', fontsize=10, fontweight='bold')

    def _add_phase_labels(self, fig, phase_boundaries, relative_times):
        """æ·»åŠ é˜¶æ®µæ ‡ç­¾"""
        if not phase_boundaries:
            return

        # è®¡ç®—é˜¶æ®µæ—¶é—´èŒƒå›´
        phases_info = []
        for i, (phase_type, idx, label) in enumerate(phase_boundaries):
            start_time = relative_times[idx] if idx < len(relative_times) else 0
            end_time = relative_times[phase_boundaries[i + 1][1]] if i + 1 < len(phase_boundaries) else relative_times[-1]
            phases_info.append((phase_type, start_time, end_time, label))

        # åœ¨å›¾è¡¨é¡¶éƒ¨æ·»åŠ é˜¶æ®µæ¡
        ax_phase = fig.add_axes([0.1, 0.95, 0.8, 0.03])
        ax_phase.set_xlim(0, relative_times[-1] if relative_times else 1)
        ax_phase.set_ylim(0, 1)
        ax_phase.axis('off')

        colors = {'training': 'lightblue', 'search': 'lightgreen', 'evaluation': 'lightcoral'}
        for phase_type, start_time, end_time, label in phases_info:
            width = end_time - start_time
            ax_phase.add_patch(Rectangle((start_time, 0), width, 1,
                                         facecolor=colors.get(phase_type, 'lightgray'),
                                         alpha=0.7, edgecolor='black'))
            ax_phase.text(start_time + width / 2, 0.5, label, ha='center', va='center',
                          fontweight='bold', fontsize=10)

    def _add_memory_analysis_annotations(self, fig, rss_values, vms_values, index_memory, other_memory):
        """æ·»åŠ å†…å­˜åˆ†ææ³¨é‡Š"""
        if not rss_values or not vms_values:
            return

        # è®¡ç®—å…³é”®æŒ‡æ ‡
        peak_rss = max(rss_values)
        peak_vms = max(vms_values)
        final_index_memory = index_memory[-1] if index_memory else 0
        final_other_memory = other_memory[-1] if other_memory else 0
        vms_rss_ratio = peak_vms / peak_rss if peak_rss > 0 else 0

        # æ·»åŠ åˆ†ææ–‡æœ¬æ¡†
        analysis_text = f"""å†…å­˜ä½¿ç”¨åˆ†æ:
å³°å€¼RSSå†…å­˜: {peak_rss:.1f} MB
å³°å€¼VMSå†…å­˜: {peak_vms:.1f} MB
VMS/RSSæ¯”ä¾‹: {vms_rss_ratio:.2f}
ç´¢å¼•å†…å­˜å æ¯”: {final_index_memory/(final_index_memory+final_other_memory)*100:.1f}%
å…¶ä»–å†…å­˜å æ¯”: {final_other_memory/(final_index_memory+final_other_memory)*100:.1f}%"""

        fig.text(0.02, 0.02, analysis_text, fontsize=10,
                 bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8),
                 verticalalignment='bottom')


# åˆ›å»ºå…¨å±€å†…å­˜ç›‘æ§å™¨
memory_monitor = AdvancedMemoryMonitor(
    enable_tracemalloc=ENABLE_DETAILED_MEMORY_MONITORING,
    log_file=MEMORY_LOG_FILENAME if ENABLE_DETAILED_MEMORY_MONITORING else None
)


# ==============================================================================
# 2. è¾…åŠ©å‡½æ•°ï¼šè¯»å–.fbinæ–‡ä»¶
# ==============================================================================
def read_fbin(filename, start_idx=0, chunk_size=None):
    """
    è¯»å–.fbinæ ¼å¼çš„æ–‡ä»¶
    æ ¼å¼: [nvecs: int32, dim: int32, data: float32[nvecs*dim]]
    """
    with open(filename, 'rb') as f:
        nvecs = struct.unpack('i', f.read(4))[0]
        dim = struct.unpack('i', f.read(4))[0]

        if chunk_size is None:
            # è¯»å–æ•´ä¸ªæ–‡ä»¶
            data = np.fromfile(f, dtype=np.float32, count=nvecs * dim)
            data = data.reshape(nvecs, dim)
            return data
        else:
            # è¯»å–æŒ‡å®šå—
            end_idx = min(start_idx + chunk_size, nvecs)
            num_vectors_in_chunk = end_idx - start_idx
            offset = start_idx * dim * 4  # æ¯ä¸ªfloat32å 4å­—èŠ‚
            f.seek(offset, os.SEEK_CUR)
            data = np.fromfile(f, dtype=np.float32, count=num_vectors_in_chunk * dim)
            data = data.reshape(num_vectors_in_chunk, dim)
            return data, nvecs, dim


def read_ivecs(filename):
    """
    (æ­¤å‡½æ•°åœ¨æ­¤è„šæœ¬ä¸­æœªç”¨äºæ‰¹é‡è¯»å–ï¼Œä»…ä½œä¸ºå·¥å…·å‡½æ•°ä¿ç•™)
    è¯»å–.ivecsæ ¼å¼çš„äºŒè¿›åˆ¶æ–‡ä»¶ (ä¾‹å¦‚SIFT1Mçš„groundtruth)
    æ ¼å¼: å‘é‡å¾ªç¯ [dim: int32, data: int32[dim]]
    """
    a = np.fromfile(filename, dtype='int32')
    d = a[0]
    return a.reshape(-1, d + 1)[:, 1:].copy()


# ==============================================================================
# 2. è®¾ç½®å‚æ•°ä¸ç¯å¢ƒ
# ==============================================================================

# ä»è®­ç»ƒæ–‡ä»¶ä¸­è·å–ç»´åº¦ä¿¡æ¯
_, nt, d_train = read_fbin(LEARN_FILE, chunk_size=1)  # åªè¯»å–å…ƒæ•°æ®

# è·å–æ•°æ®é›†å¤§å°ä¿¡æ¯
_, nb, d_base = read_fbin(BASE_FILE, chunk_size=1)
_, nq, d_query = read_fbin(QUERY_FILE, chunk_size=1)

# éªŒè¯ç»´åº¦ä¸€è‡´æ€§
if d_train != d_base or d_train != d_query:
    raise ValueError(f"ç»´åº¦ä¸ä¸€è‡´: è®­ç»ƒé›†{d_train}ç»´, åŸºç¡€é›†{d_base}ç»´, æŸ¥è¯¢é›†{d_query}ç»´")

# è®¾ç½®å…¶ä»–å‚æ•°
cell_size = 256
nlist = nb // cell_size
nprobe = 32
chunk_size = 100000  # æ¯æ¬¡å¤„ç†çš„æ•°æ®å—å¤§å°
k = 10  # æŸ¥æ‰¾æœ€è¿‘çš„10ä¸ªé‚»å±…

M = 32  # HNSWçš„è¿æ¥æ•°
efconstruction = 40  # é»˜è®¤40
efsearch = 16  # é»˜è®¤16

# ==============================================================================
# ã€é‡æ„ç‚¹ã€‘: åœ¨ç´¢å¼•æ–‡ä»¶åä¸­åŒæ—¶ä½“ç° M å’Œ efConstruction çš„å€¼
# ==============================================================================
base_name = os.path.splitext(os.path.basename(BASE_FILE))[0]
# æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
clean_base_name = re.sub(r'[^a-zA-Z0-9_]', '_', base_name)
# åœ¨æ–‡ä»¶åä¸­æ·»åŠ  M å’Œ efc å‚æ•°ï¼Œä»¥åŒºåˆ†ä¸åŒå‚æ•°æ„å»ºçš„ç´¢å¼•
INDEX_FILE = os.path.join(DATA_DIR,
                          f"{clean_base_name}_d{d_train}_nlist{nlist}_HNSWM{M}_efc{efconstruction}_IVFFlat.index")
# ==============================================================================

print("=" * 60)
print("Phase 0: ç¯å¢ƒè®¾ç½®")
print(f"å‘é‡ç»´åº¦ (d): {d_train}")
print(f"åŸºç¡€é›†å¤§å° (nb): {nb}, è®­ç»ƒé›†å¤§å° (ntrain): {nt}")
print(f"æŸ¥è¯¢é›†å¤§å° (nq): {nq}, åˆ†å—å¤§å° (chunk_size): {chunk_size}")
print(f"HNSW M (æ„å»ºå‚æ•°): {M}")
print(f"HNSW efConstruction (æ„å»ºå‚æ•°): {efconstruction}")
print(f"ç´¢å¼•å°†ä¿å­˜åœ¨ç£ç›˜æ–‡ä»¶: {INDEX_FILE}")
print(f"IVFç»Ÿè®¡åŠŸèƒ½: {'å¯ç”¨' if ENABLE_IVF_STATS else 'ç¦ç”¨'}")
print(f"æœç´¢åˆ†åŒºç»Ÿè®¡åŠŸèƒ½: {'å¯ç”¨' if ENABLE_SEARCH_PARTITION_STATS else 'ç¦ç”¨'}")
print(f"è¯¦ç»†å†…å­˜ç›‘æ§: {'å¯ç”¨' if ENABLE_DETAILED_MEMORY_MONITORING else 'ç¦ç”¨'}")
print("=" * 60)

# è®°å½•åˆå§‹å†…å­˜çŠ¶æ€
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("ç¨‹åºå¼€å§‹")

# ==============================================================================
# 3. æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
# ==============================================================================
if os.path.exists(INDEX_FILE):
    print(f"ç´¢å¼•æ–‡ä»¶ {INDEX_FILE} å·²å­˜åœ¨ï¼Œè·³è¿‡ç´¢å¼•æ„å»ºé˜¶æ®µ")
    skip_index_building = True
else:
    print("ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†æ„å»ºæ–°ç´¢å¼•")
    skip_index_building = False

# ==============================================================================
# 4. è®­ç»ƒé‡åŒ–å™¨
# ==============================================================================
if not skip_index_building:
    if ENABLE_DETAILED_MEMORY_MONITORING:
        with memory_monitor.monitor_phase("è®­ç»ƒHNSWç²—é‡åŒ–å™¨"):
            print("\nPhase 1: è®­ç»ƒ HNSW ç²—é‡åŒ–å™¨ (in-memory)")
            coarse_quantizer = faiss.IndexHNSWFlat(d_train, M, faiss.METRIC_L2)
            coarse_quantizer.hnsw.efConstruction = efconstruction
            coarse_quantizer.hnsw.efSearch = efsearch
            print(f"efconstruction: {coarse_quantizer.hnsw.efConstruction}, efSearch: {coarse_quantizer.hnsw.efSearch}")
            # coarse_quantizer = faiss.IndexFlatL2(d_train)
            index_for_training = faiss.IndexIVFFlat(coarse_quantizer, d_train, nlist, faiss.METRIC_L2)
            index_for_training.verbose = True

            xt = read_fbin(LEARN_FILE)

            print("è®­ç»ƒèšç±»ä¸­å¿ƒå¹¶æ„å»º HNSW é‡åŒ–å™¨...")
            start_time = time.time()
            index_for_training.train(xt)
            end_time = time.time()

            print(f"é‡åŒ–å™¨è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
            print(f"ç²—é‡åŒ–å™¨ä¸­çš„è´¨å¿ƒæ•°é‡: {coarse_quantizer.ntotal}")
            del xt
            del index_for_training

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            memory_monitor.force_gc_and_log("è®­ç»ƒå®Œæˆå")
    else:
        print("\nPhase 1: è®­ç»ƒ HNSW ç²—é‡åŒ–å™¨ (in-memory)")
        coarse_quantizer = faiss.IndexHNSWFlat(d_train, M, faiss.METRIC_L2)
        coarse_quantizer.hnsw.efConstruction = efconstruction
        coarse_quantizer.hnsw.efSearch = efsearch
        print(f"efconstruction: {coarse_quantizer.hnsw.efConstruction}, efSearch: {coarse_quantizer.hnsw.efSearch}")
        # coarse_quantizer = faiss.IndexFlatL2(d_train)
        index_for_training = faiss.IndexIVFFlat(coarse_quantizer, d_train, nlist, faiss.METRIC_L2)
        index_for_training.verbose = True

        xt = read_fbin(LEARN_FILE)

        print("è®­ç»ƒèšç±»ä¸­å¿ƒå¹¶æ„å»º HNSW é‡åŒ–å™¨...")
        start_time = time.time()
        index_for_training.train(xt)
        end_time = time.time()

        print(f"é‡åŒ–å™¨è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"ç²—é‡åŒ–å™¨ä¸­çš„è´¨å¿ƒæ•°é‡: {coarse_quantizer.ntotal}")
        del xt
        del index_for_training

    # ==============================================================================
    # 5. åˆ›å»ºä¸€ä¸ªç©ºçš„ã€åŸºäºç£ç›˜çš„ç´¢å¼•æ¡†æ¶
    # ==============================================================================
    print("\nPhase 2: åˆ›å»ºç©ºçš„ç£ç›˜ç´¢å¼•æ¡†æ¶")
    index_shell = faiss.IndexIVFFlat(coarse_quantizer, d_train, nlist, faiss.METRIC_L2)
    print(f"å°†ç©ºçš„ç´¢å¼•æ¡†æ¶å†™å…¥ç£ç›˜: {INDEX_FILE}")
    faiss.write_index(index_shell, INDEX_FILE)
    del index_shell

    # ==============================================================================
    # 6. åˆ†å—å‘ç£ç›˜ç´¢å¼•ä¸­æ·»åŠ æ•°æ® (ä»base.fbin)
    # ==============================================================================
    if ENABLE_DETAILED_MEMORY_MONITORING:
        with memory_monitor.monitor_phase("åˆ†å—æ·»åŠ æ•°æ®åˆ°ç£ç›˜ç´¢å¼•"):
            print("\nPhase 3: åˆ†å—æ·»åŠ æ•°æ®åˆ°ç£ç›˜ç´¢å¼•")

            # å…¼å®¹ä¸åŒFaissç‰ˆæœ¬çš„IOæ ‡å¿—å¤„ç†
            try:
                IO_FLAG_READ_WRITE = faiss.IO_FLAG_READ_WRITE
            except AttributeError:
                try:
                    IO_FLAG_READ_WRITE = faiss.index_io.IO_FLAG_READ_WRITE
                except AttributeError:
                    IO_FLAG_READ_WRITE = 0

            print(f"ä½¿ç”¨IOæ ‡å¿—: {IO_FLAG_READ_WRITE} (è¯»å†™æ¨¡å¼)")

            index_ondisk = faiss.read_index(INDEX_FILE, IO_FLAG_READ_WRITE)
            start_time = time.time()

            num_chunks = (nb + chunk_size - 1) // chunk_size
            for i in range(0, nb, chunk_size):
                chunk_idx = i // chunk_size + 1
                print(f"       -> æ­£åœ¨å¤„ç†å— {chunk_idx}/{num_chunks}: å‘é‡ {i} åˆ° {min(i + chunk_size, nb) - 1}")

                # ä»base.fbinä¸­è¯»å–æ•°æ®å—
                xb_chunk, _, _ = read_fbin(BASE_FILE, i, chunk_size)

                index_ondisk.add(xb_chunk)
                del xb_chunk

                # æ¯å¤„ç†10ä¸ªå—è¿›è¡Œä¸€æ¬¡å†…å­˜ç›‘æ§
                if chunk_idx % 10 == 0:
                    memory_monitor.log_memory_snapshot(f"å¤„ç†å—{chunk_idx}")

            print(f"\næ‰€æœ‰æ•°æ®å—æ·»åŠ å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
            print(f"ç£ç›˜ç´¢å¼•ä¸­çš„å‘é‡æ€»æ•° (ntotal): {index_ondisk.ntotal}")

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            memory_monitor.force_gc_and_log("åˆ†å—æ·»åŠ å®Œæˆå")
    else:
        print("\nPhase 3: åˆ†å—æ·»åŠ æ•°æ®åˆ°ç£ç›˜ç´¢å¼•")

        # å…¼å®¹ä¸åŒFaissç‰ˆæœ¬çš„IOæ ‡å¿—å¤„ç†
        try:
            IO_FLAG_READ_WRITE = faiss.IO_FLAG_READ_WRITE
        except AttributeError:
            try:
                IO_FLAG_READ_WRITE = faiss.index_io.IO_FLAG_READ_WRITE
            except AttributeError:
                IO_FLAG_READ_WRITE = 0

        print(f"ä½¿ç”¨IOæ ‡å¿—: {IO_FLAG_READ_WRITE} (è¯»å†™æ¨¡å¼)")

        index_ondisk = faiss.read_index(INDEX_FILE, IO_FLAG_READ_WRITE)
        start_time = time.time()

        num_chunks = (nb + chunk_size - 1) // chunk_size
        for i in range(0, nb, chunk_size):
            chunk_idx = i // chunk_size + 1
            print(f"       -> æ­£åœ¨å¤„ç†å— {chunk_idx}/{num_chunks}: å‘é‡ {i} åˆ° {min(i + chunk_size, nb) - 1}")

            # ä»base.fbinä¸­è¯»å–æ•°æ®å—
            xb_chunk, _, _ = read_fbin(BASE_FILE, i, chunk_size)

            index_ondisk.add(xb_chunk)
            del xb_chunk

        print(f"\næ‰€æœ‰æ•°æ®å—æ·»åŠ å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
        print(f"ç£ç›˜ç´¢å¼•ä¸­çš„å‘é‡æ€»æ•° (ntotal): {index_ondisk.ntotal}")

    # ===========================================================
    # 7. æ–°å¢: è¾“å‡ºIVFåˆ†åŒºç»Ÿè®¡ä¿¡æ¯ (ä»…åœ¨æ„å»ºç´¢å¼•æ—¶æ‰§è¡Œ)
    # ===========================================================
    if ENABLE_IVF_STATS and not skip_index_building:
        print("\nè¾“å‡ºIVFåˆ†åŒºç»Ÿè®¡ä¿¡æ¯...")
        start_stats_time = time.time()

        # è·å–å€’æ’åˆ—è¡¨
        invlists = index_ondisk.invlists

        # å‡†å¤‡ç»Ÿè®¡ä¿¡æ¯
        partition_stats = []
        non_empty_partitions = 0
        max_size = 0
        min_size = float('inf')
        total_vectors = 0

        # éå†æ‰€æœ‰åˆ†åŒº
        for list_id in range(nlist):
            list_size = invlists.list_size(list_id)

            # ä¿®æ”¹ç‚¹ 1ï¼šæ— è®ºåˆ†åŒºå¤§å°æ˜¯å¦ä¸º0ï¼Œéƒ½è®°å½•ä¸‹æ¥ï¼Œä»¥ä¾¿ç”Ÿæˆå®Œæ•´çš„CSVæŠ¥å‘Š
            partition_stats.append((list_id, list_size))

            # ä»…é’ˆå¯¹éç©ºåˆ†åŒºæ›´æ–°æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯
            if list_size > 0:
                non_empty_partitions += 1
                max_size = max(max_size, list_size)
                min_size = min(min_size, list_size)
                total_vectors += list_size

        # ä¿®æ”¹ç‚¹ 2ï¼šå¤„ç†æ²¡æœ‰éç©ºåˆ†åŒºçš„è¾¹ç¼˜æƒ…å†µï¼Œé¿å…æ‰“å° 'inf'
        if non_empty_partitions == 0:
            min_size = 0

        # è®¡ç®—éç©ºåˆ†åŒºçš„å¹³å‡å¤§å° (total_vectors æ˜¯éç©ºåˆ†åŒºä¸­çš„å‘é‡æ€»æ•°)
        avg_size = total_vectors / non_empty_partitions if non_empty_partitions > 0 else 0

        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        print(f"IVFåˆ†åŒºç»Ÿè®¡æ‘˜è¦:")
        print(f"  åˆ†åŒºæ€»æ•°: {nlist}")
        print(f"  éç©ºåˆ†åŒºæ•°: {non_empty_partitions} ({non_empty_partitions / nlist * 100:.2f}%)")
        print(f"  æœ€å¤§åˆ†åŒºå¤§å°: {max_size}")
        # ä¿®æ”¹ç‚¹ 3ï¼šä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæ˜ç¡®æŒ‡å‡ºè¿™æ˜¯éç©ºåˆ†åŒºçš„æœ€å°å€¼
        print(f"  æœ€å°(éç©º)åˆ†åŒºå¤§å°: {min_size}")
        # ä¿®æ”¹ç‚¹ 3ï¼šä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæ˜ç¡®æŒ‡å‡ºè¿™æ˜¯éç©ºåˆ†åŒºçš„å¹³å‡å€¼
        print(f"  å¹³å‡(éç©º)åˆ†åŒºå¤§å°: {avg_size:.2f}")

        # å°†è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯å†™å…¥æ–‡ä»¶
        # æ­¤éƒ¨åˆ†æ— éœ€ä¿®æ”¹ï¼Œå› ä¸ºå®ƒç°åœ¨ä¼šæ­£ç¡®å¤„ç†åŒ…å«æ‰€æœ‰åˆ†åŒºçš„ partition_stats åˆ—è¡¨
        stats_filename = os.path.splitext(INDEX_FILE)[0] + "_ivf_stats.csv"
        with open(stats_filename, 'w') as f:
            f.write("partition_id,vector_count\n")
            for list_id, size in partition_stats:
                f.write(f"{list_id},{size}\n")

        print(f"åˆ†åŒºç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_filename}")
        print(f"ç»Ÿè®¡è€—æ—¶: {time.time() - start_stats_time:.2f}ç§’")

    # ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜
    print(f"æ­£åœ¨å°†æœ€ç»ˆç´¢å¼•å†™å›ç£ç›˜: {INDEX_FILE}")
    faiss.write_index(index_ondisk, INDEX_FILE)
    del index_ondisk

# ==============================================================================
# 8. ä½¿ç”¨å†…å­˜æ˜ å°„ (mmap) è¿›è¡Œæœç´¢ (ä½¿ç”¨query.fbin)
# ==============================================================================
print("\nPhase 4: ä½¿ç”¨å†…å­˜æ˜ å°„æ¨¡å¼è¿›è¡Œæœç´¢")
print(f"ä»¥ mmap æ¨¡å¼æ‰“å¼€ç£ç›˜ç´¢å¼•: {INDEX_FILE}")

# å…¼å®¹ä¸åŒFaissç‰ˆæœ¬çš„IOæ ‡å¿—å¤„ç†
try:
    IO_FLAG_MMAP = faiss.IO_FLAG_MMAP
except AttributeError:
    try:
        IO_FLAG_MMAP = faiss.index_io.IO_FLAG_MMAP
    except AttributeError:
        IO_FLAG_MMAP = 4

print(f"ä½¿ç”¨IOæ ‡å¿—: {IO_FLAG_MMAP} (å†…å­˜æ˜ å°„æ¨¡å¼)")

index_final = faiss.read_index(INDEX_FILE, IO_FLAG_MMAP)
index_final.nprobe = nprobe
# index_final.quantizer.hnsw.efSearch = 100  # è®¾ç½®HNSWçš„efSearchå‚æ•°ä»¥åŒ¹é…nprobe
faiss.omp_set_num_threads(40)
index_final.parallel_mode = 0
print(f"å¹¶è¡Œæ¨¡å¼çº¿ç¨‹æ•°: {faiss.omp_get_max_threads()}")
print(f"å¹¶è¡Œæ¨¡å¼: {index_final.parallel_mode}")
print(f"ç´¢å¼•å·²å‡†å¤‡å¥½æœç´¢ (nprobe={index_final.nprobe})")
generic_quantizer = index_final.quantizer
quantizer_hnsw = faiss.downcast_index(generic_quantizer)
quantizer_hnsw.hnsw.efSearch = efsearch
print(f"efConstruction: {quantizer_hnsw.hnsw.efConstruction}, efSearch: {quantizer_hnsw.hnsw.efSearch}")

# è®¾ç½®ç´¢å¼•å†…å­˜åŸºçº¿
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("ç´¢å¼•åŠ è½½å®Œæˆ")
    # ä¼°ç®—ç´¢å¼•å¤§å°ï¼ˆåŸºäºç´¢å¼•æ–‡ä»¶å¤§å°ï¼‰
    index_file_size_mb = os.path.getsize(INDEX_FILE) / (1024 * 1024)
    memory_monitor.set_index_memory_baseline(index_file_size_mb * 0.8)  # å‡è®¾80%çš„ç´¢å¼•æ–‡ä»¶è¢«åŠ è½½åˆ°å†…å­˜

print("ä» query.fbin åŠ è½½æŸ¥è¯¢å‘é‡...")
xq = read_fbin(QUERY_FILE)

# è®°å½•æŸ¥è¯¢å‘é‡åŠ è½½åçš„å†…å­˜çŠ¶æ€
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("æŸ¥è¯¢å‘é‡åŠ è½½å®Œæˆ")

# åœ¨æœç´¢å‰è¿›è¡Œå†…å­˜ä¼˜åŒ–
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.force_gc_and_log("æœç´¢å‰ä¼˜åŒ–")

# ==============================================================================
# 8.5. æ–°å¢: ç»Ÿè®¡å¹¶ä¿å­˜æ¯ä¸ªæŸ¥è¯¢å‘½ä¸­çš„åˆ†åŒºç‚¹æ•°å æ€»ç‚¹æ•°çš„æ¯”ä¾‹
# ==============================================================================
if ENABLE_SEARCH_PARTITION_STATS:
    print("\n" + "=" * 60)
    print(f"Phase 4.5: ç»Ÿè®¡æœç´¢åˆ†åŒºä¿¡æ¯ (nprobe={nprobe})")

    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦ä¸ºIVFç±»å‹ï¼Œå› ä¸ºè¯¥é€»è¾‘ä¾èµ–äºquantizerå’Œinvlists
    if not isinstance(index_final, faiss.IndexIVF):
        print("é”™è¯¯ï¼šç´¢å¼•ç±»å‹ä¸æ˜¯IndexIVFï¼Œæ— æ³•æ‰§è¡Œåˆ†åŒºç»Ÿè®¡ã€‚")
    else:
        total_vectors_in_index = index_final.ntotal
        print(f"ç´¢å¼•ä¸­çš„æ€»å‘é‡æ•°: {total_vectors_in_index}")

        if total_vectors_in_index == 0:
            print("è­¦å‘Šï¼šç´¢å¼•ä¸­æ²¡æœ‰å‘é‡ï¼Œæ‰€æœ‰æ¯”ä¾‹å°†ä¸º0ã€‚")

        print("æ­£åœ¨ä¸ºæ¯ä¸ªæŸ¥è¯¢å‘é‡æŸ¥æ‰¾å¯¹åº”çš„åˆ†åŒº...")
        # 1. å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡ï¼Œç”¨ç²—é‡åŒ–å™¨æ‰¾åˆ°nprobeä¸ªæœ€è¿‘çš„ç°‡å¿ƒ(åˆ†åŒº)
        # I_quant çš„ç»´åº¦æ˜¯ (nq, nprobe)ï¼Œå­˜å‚¨äº†æ¯ä¸ªæŸ¥è¯¢å‘½ä¸­çš„åˆ†åŒºID
        _, I_quant = index_final.quantizer.search(xq, nprobe)

        ratios = []
        print(f"æ­£åœ¨è®¡ç®— {nq} ä¸ªæŸ¥è¯¢çš„å‘½ä¸­åˆ†åŒºç‚¹æ•°æ¯”ä¾‹...")

        # 2. éå†æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœ
        for i in range(nq):
            probed_list_ids = I_quant[i]

            # 3. ç´¯åŠ è¿™äº›åˆ†åŒºä¸­çš„å‘é‡æ€»æ•°
            num_vectors_in_probed_partitions = 0
            for list_id in probed_list_ids:
                if list_id >= 0:  # æœ‰æ•ˆçš„åˆ†åŒºID
                    num_vectors_in_probed_partitions += index_final.invlists.list_size(int(list_id))

            # 4. è®¡ç®—æ¯”ä¾‹
            ratio = num_vectors_in_probed_partitions / total_vectors_in_index if total_vectors_in_index > 0 else 0
            ratios.append(ratio)

        # 5. å°†ç»“æœå†™å…¥æ–‡ä»¶
        try:
            with open(SEARCH_STATS_FILENAME, 'w') as f:
                for ratio in ratios:
                    f.write(f"{ratio:.8f}\n")  # å†™å…¥æ—¶ä¿ç•™8ä½å°æ•°
            print(f"æœç´¢åˆ†åŒºç»Ÿè®¡æ¯”ä¾‹å·²æˆåŠŸå†™å…¥æ–‡ä»¶: {SEARCH_STATS_FILENAME}")
        except IOError as e:
            print(f"é”™è¯¯ï¼šæ— æ³•å†™å…¥ç»Ÿè®¡æ–‡ä»¶ {SEARCH_STATS_FILENAME}ã€‚åŸå› : {e}")

    print("=" * 60)


if ENABLE_DETAILED_MEMORY_MONITORING:
    with memory_monitor.monitor_phase("æ‰§è¡Œæœç´¢"):
        print("\næ‰§è¡Œæœç´¢...")
        start_time = time.time()
        D, I = index_final.search(xq, k)
        end_time = time.time()

        # æœç´¢åç«‹å³è®°å½•å†…å­˜çŠ¶æ€
        memory_monitor.log_memory_snapshot("æœç´¢å®Œæˆ")
else:
    print("\næ‰§è¡Œæœç´¢...")
    start_time = time.time()
    D, I = index_final.search(xq, k)
    end_time = time.time()

# ä» .indexIVF_stats å±æ€§ä¸­è·å–ç»Ÿè®¡å¯¹è±¡
stats = faiss.cvar.indexIVF_stats

print("\n========== æœç´¢æ€§èƒ½ç»Ÿè®¡ ==========")
print(f"æŸ¥è¯¢å‘é‡æ€»æ•° (nq): {stats.nq}")
print(f"æ€»æœç´¢æ—¶é—´ (search_time): {stats.search_time:.3f} ms")
print(f"  - ç²—ç­›é˜¶æ®µç”¨æ—¶ (quantization_time): {stats.quantization_time:.3f} ms")
# ç²¾ç­›æ—¶é—´å¯ä»¥é€šè¿‡æ€»æ—¶é—´å‡å»ç²—ç­›æ—¶é—´å¾—åˆ°
print(f"  - ç²¾ç­›é˜¶æ®µç”¨æ—¶ (search_time - quantization_time): {stats.search_time - stats.quantization_time:.3f} ms")
print("-" * 30)
print(f"è®¿é—®çš„å€’æ’åˆ—è¡¨æ€»æ•° (nlist): {stats.nlist}")
print(f"è®¡ç®—çš„å‘é‡è·ç¦»æ€»æ•° (ndis): {stats.ndis}")
print(f"ç»“æœå †çš„æ›´æ–°æ€»æ¬¡æ•° (nheap_updates): {stats.nheap_updates}")
print("====================================\n")

# --- æ–°å¢QPSè®¡ç®— ---
search_duration = end_time - start_time
print(f"æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_duration:.2f} ç§’")

if search_duration > 0:
    qps = nq / search_duration
    print(f"QPS (æ¯ç§’æŸ¥è¯¢ç‡): {qps:.2f}")
else:
    print("æœç´¢è€—æ—¶è¿‡çŸ­ï¼Œæ— æ³•è®¡ç®—QPS")
# --- QPSè®¡ç®—ç»“æŸ ---


# ==============================================================================
# 9.  æ–°å¢: æ ¹æ®Groundtruthè®¡ç®—å¬å›ç‡ (å†…å­˜ä¼˜åŒ–ç‰ˆ)
# ==============================================================================
print("\n" + "=" * 60)
print("Phase 5: è®¡ç®—å¬å›ç‡ (å†…å­˜ä¼˜åŒ–ç‰ˆ)")

if not os.path.exists(GROUNDTRUTH_FILE):
    print(f"Groundtruthæ–‡ä»¶æœªæ‰¾åˆ°: {GROUNDTRUTH_FILE}")
    print("è·³è¿‡å¬å›ç‡è®¡ç®—ã€‚")
else:
    print(f"ä»¥æµå¼æ–¹å¼ä» {GROUNDTRUTH_FILE} è¯»å– groundtruth æ•°æ®è¿›è¡Œè®¡ç®—...")

    total_found = 0

    # ä½¿ç”¨withè¯­å¥ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å…³é—­
    with open(GROUNDTRUTH_FILE, 'rb') as f:
        # é¦–å…ˆï¼Œä»æ–‡ä»¶çš„ç¬¬ä¸€ä¸ªæ•´æ•°ç¡®å®šgroundtruthçš„ç»´åº¦ (k_gt)
        dim_bytes = f.read(4)
        if not dim_bytes:
            raise EOFError("Groundtruth æ–‡ä»¶ä¸ºç©ºæˆ–å·²æŸåã€‚")
        k_gt = struct.unpack('i', dim_bytes)[0]

        print(f"Groundtruth ç»´åº¦ (k_gt): {k_gt}")

        # è®¡ç®—æ–‡ä»¶ä¸­æ¯æ¡è®°å½•çš„å­—èŠ‚å¤§å°
        # æ¯æ¡è®°å½•åŒ…å«1ä¸ªç»´åº¦æ•´æ•°å’Œk_gtä¸ªIDæ•´æ•°ï¼Œæ¯ä¸ªæ•´æ•°4å­—èŠ‚
        record_size_bytes = (k_gt + 1) * 4

        # éªŒè¯æ–‡ä»¶ä¸­çš„å‘é‡æ•°é‡æ˜¯å¦ä¸æŸ¥è¯¢æ•°é‡(nq)åŒ¹é…
        f.seek(0, os.SEEK_END)
        total_file_size = f.tell()
        num_gt_vectors = total_file_size // record_size_bytes
        if nq != num_gt_vectors:
            print(f"è­¦å‘Š: æŸ¥è¯¢æ•°é‡({nq})ä¸groundtruthä¸­çš„æ•°é‡({num_gt_vectors})ä¸åŒ¹é…!")

        print(f"æ­£åœ¨è®¡ç®— Recall@{k}...")

        # éå†æ¯ä¸ªæŸ¥è¯¢ç»“æœ
        for i in range(nq):
            # è®¡ç®—ç¬¬ i æ¡è®°å½•åœ¨æ–‡ä»¶ä¸­çš„èµ·å§‹ä½ç½®
            offset = i * record_size_bytes
            f.seek(offset)

            # ä»è¯¥ä½ç½®è¯»å–ä¸€æ¡å®Œæ•´çš„è®°å½• (k_gt + 1 ä¸ªæ•´æ•°)
            record_data = np.fromfile(f, dtype=np.int32, count=k_gt + 1)

            # è®°å½•ä¸­çš„ç¬¬ä¸€ä¸ªæ•´æ•°æ˜¯ç»´åº¦ï¼Œæˆ‘ä»¬æå–ä»ç¬¬äºŒä¸ªå…ƒç´ å¼€å§‹çš„IDåˆ—è¡¨
            gt_i = record_data[1:]

            found_count = np.isin(I[i], gt_i[:k]).sum()
            total_found += found_count

    # å¬å›ç‡ = (æ‰€æœ‰æŸ¥è¯¢æ‰¾åˆ°çš„æ­£ç¡®è¿‘é‚»æ€»æ•°) / (æ‰€æœ‰æŸ¥è¯¢è¿”å›çš„ç»“æœæ€»æ•°)
    recall = total_found / (nq * k)

    print(f"\næŸ¥è¯¢äº† {nq} ä¸ªå‘é‡, k={k}")
    print(f"åœ¨top-{k}çš„ç»“æœä¸­ï¼Œæ€»å…±æ‰¾åˆ°äº† {total_found} ä¸ªçœŸå®çš„è¿‘é‚»ã€‚")
    print(f"Recall@{k}: {recall:.4f}")

    # è®°å½•å¬å›ç‡è®¡ç®—åçš„å†…å­˜çŠ¶æ€
    if ENABLE_DETAILED_MEMORY_MONITORING:
        memory_monitor.log_memory_snapshot("å¬å›ç‡è®¡ç®—å®Œæˆ")

print("=" * 60)

# ==============================================================================
# 10. æŠ¥å‘Šå³°å€¼å†…å­˜
# ==============================================================================
print("\n" + "=" * 60)
print("å†…å­˜ä½¿ç”¨æƒ…å†µæŠ¥å‘Š")
print("=" * 60)

# ä¼ ç»Ÿæ–¹æ³•ï¼ˆresource.getrusageï¼‰
if platform.system() in ["Linux", "Darwin"]:
    peak_memory_bytes = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    if platform.system() == "Linux":
        peak_memory_bytes *= 1024
    peak_memory_mb = peak_memory_bytes / (1024 * 1024)
    print(f"ä¼ ç»Ÿæ–¹æ³• - æ•´ä¸ªç¨‹åºè¿è¡ŒæœŸé—´çš„å³°å€¼å†…å­˜å ç”¨: {peak_memory_mb:.2f} MB")

# æ–°çš„è¯¦ç»†å†…å­˜åˆ†æ
if ENABLE_DETAILED_MEMORY_MONITORING:
    print("\nè¯¦ç»†å†…å­˜åˆ†æ:")
    summary = memory_monitor.get_memory_summary()
    if summary:
        print(f"  å³°å€¼RSSå†…å­˜: {summary['peak_rss_mb']:.2f} MB")
        print(f"  å³°å€¼VMSå†…å­˜: {summary['peak_vms_mb']:.2f} MB")
        print(f"  å¹³å‡RSSå†…å­˜: {summary['avg_rss_mb']:.2f} MB")
        print(f"  å¹³å‡VMSå†…å­˜: {summary['avg_vms_mb']:.2f} MB")
        print(f"  æ€»ç›‘æ§å¿«ç…§æ•°: {summary['total_snapshots']}")

    # å†…å­˜å¢é•¿æ¨¡å¼åˆ†æ
    print("\nå†…å­˜å¢é•¿æ¨¡å¼åˆ†æ:")
    growth_analysis = memory_monitor.analyze_memory_growth_pattern()
    if growth_analysis:
        print(f"  æ€»å†…å­˜å¢é•¿: {growth_analysis['total_growth_mb']:.2f} MB")
        print(f"  å³°å€¼ä½¿ç”¨: {growth_analysis['peak_usage_mb']:.2f} MB")
        print("  å„é˜¶æ®µå†…å­˜å¢é•¿:")
        for phase_info in growth_analysis['growth_phases']:
            print(f"    {phase_info['phase']}: +{phase_info['growth_mb']:.2f} MB (æ€»è®¡: {phase_info['rss_mb']:.2f} MB)")

    # å†…å­˜åˆ†è§£åˆ†æ
    print("\nå†…å­˜ä½¿ç”¨åˆ†è§£:")
    final_info = memory_monitor.get_memory_info()
    print(
        f"  ç´¢å¼•å†…å­˜: {final_info['index_memory_mb']:.2f} MB ({final_info['index_memory_mb'] / final_info['rss_mb'] * 100:.1f}%)")
    print(
        f"  å…¶ä»–å†…å­˜: {final_info['other_memory_mb']:.2f} MB ({final_info['other_memory_mb'] / final_info['rss_mb'] * 100:.1f}%)")

    # æ˜¾ç¤ºtracemallocç»Ÿè®¡ä¿¡æ¯
    print("\nå†…å­˜ä½¿ç”¨çƒ­ç‚¹åˆ†æ:")
    memory_monitor.get_tracemalloc_top_stats(10)

    # æœ€ç»ˆå†…å­˜çŠ¶æ€
    print(f"\næœ€ç»ˆå†…å­˜çŠ¶æ€:")
    print(f"  RSSå†…å­˜: {final_info['rss_mb']:.2f} MB")
    print(f"  VMSå†…å­˜: {final_info['vms_mb']:.2f} MB")
    print(f"  VMS/RSSæ¯”ä¾‹: {final_info['vms_mb'] / final_info['rss_mb']:.2f}")
    print(f"  Pythonå¯¹è±¡æ•°: {final_info['python_objects']}")
    if 'traced_current_mb' in final_info:
        print(f"  Tracedå†…å­˜: {final_info['traced_current_mb']:.2f} MB")

    # å†…å­˜ä¼˜åŒ–å»ºè®®
    print("\nå†…å­˜ä¼˜åŒ–å»ºè®®:")
    suggestions = memory_monitor.get_memory_optimization_suggestions()
    if suggestions:
        for suggestion in suggestions:
            print(f"  {suggestion}")
    else:
        print("  âœ… å†…å­˜ä½¿ç”¨æƒ…å†µè‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")

    print(f"\nå†…å­˜æ—¥å¿—å·²ä¿å­˜åˆ°: {MEMORY_LOG_FILENAME}")

    # ç”Ÿæˆå†…å­˜å¯è§†åŒ–å›¾è¡¨
    if ENABLE_MEMORY_VISUALIZATION:
        print("\næ­£åœ¨ç”Ÿæˆå†…å­˜ä½¿ç”¨æƒ…å†µå¯è§†åŒ–å›¾è¡¨...")
        memory_monitor.generate_memory_visualization(MEMORY_PLOT_FILENAME)
    
    # ç”Ÿæˆæœ€ç»ˆçš„å†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨
    if ENABLE_FINAL_MEMORY_PLOT:
        print("\næ­£åœ¨ç”Ÿæˆæœ€ç»ˆå†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨...")
        memory_monitor.generate_final_memory_plot(FINAL_MEMORY_PLOT_FILENAME)
else:
    print("è¯¦ç»†å†…å­˜ç›‘æ§å·²ç¦ç”¨")

print("=" * 60)