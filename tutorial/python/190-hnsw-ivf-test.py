import numpy as np
import faiss
import time
import os
import platform
import resource
import struct
import re
import psutil
import tracemalloc
import gc
from contextlib import contextmanager
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime
import threading
import queue

# ==============================================================================
# 0. è·¯å¾„å’Œæ–‡ä»¶åé…ç½® & è°ƒè¯•å¼€å…³
# ==============================================================================
DATA_DIR = "./sift"
LEARN_FILE = os.path.join(DATA_DIR, "learn.fbin")
BASE_FILE = os.path.join(DATA_DIR, "base.fbin")
QUERY_FILE = os.path.join(DATA_DIR, "query.fbin")
GROUNDTRUTH_FILE = os.path.join(DATA_DIR, "groundtruth.ivecs")

# è°ƒè¯•å¼€å…³
ENABLE_IVF_STATS = False  # æ§åˆ¶æ˜¯å¦è¾“å‡ºIVFåˆ†åŒºç»Ÿè®¡ä¿¡æ¯

# æ–°å¢å¼€å…³ - æ§åˆ¶æ˜¯å¦ç»Ÿè®¡æœç´¢åˆ†åŒºä¿¡æ¯
ENABLE_SEARCH_PARTITION_STATS = False
SEARCH_STATS_FILENAME = os.path.join(DATA_DIR, "search_partition_ratios.txt")

# å†…å­˜ç›‘æ§å¼€å…³
ENABLE_DETAILED_MEMORY_MONITORING = True
MEMORY_LOG_FILENAME = os.path.join(DATA_DIR, "memory_usage_log.txt")

# å†…å­˜å¯è§†åŒ–å¼€å…³
ENABLE_MEMORY_VISUALIZATION = True  # æ§åˆ¶æ˜¯å¦ç”Ÿæˆå†…å­˜ä½¿ç”¨å›¾è¡¨
MEMORY_PLOT_FILENAME = os.path.join(DATA_DIR, "memory_usage_plot.png")

# è¿è¡Œç»“æŸæ—¶å†…å­˜å›¾è¡¨é…ç½®
ENABLE_FINAL_MEMORY_PLOT = True  # æ§åˆ¶æ˜¯å¦åœ¨è¿è¡Œç»“æŸæ—¶ç”Ÿæˆå†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨
FINAL_MEMORY_PLOT_FILENAME = os.path.join(DATA_DIR, "final_memory_usage_plot.png")

# è¿ç»­å†…å­˜ç›‘æ§é…ç½®
ENABLE_CONTINUOUS_MONITORING = True  # å¯ç”¨è¿ç»­å†…å­˜ç›‘æ§
MEMORY_SAMPLING_INTERVAL = 0.1  # æ›´é«˜é¢‘ç‡
MEMORY_CHANGE_THRESHOLD = 5.0   # æ›´æ•æ„Ÿé˜ˆå€¼

# å†…å­˜ä¼˜åŒ–é…ç½®
MEMORY_OPTIMIZATION_CONFIG = {
    'enable_gc_before_search': True,  # æœç´¢å‰è¿›è¡Œåƒåœ¾å›æ”¶
    'enable_gc_after_search': True,  # æœç´¢åè¿›è¡Œåƒåœ¾å›æ”¶
    'gc_threshold_mb': 100,  # å†…å­˜å¢é•¿è¶…è¿‡æ­¤å€¼æ—¶è§¦å‘GC
    'max_memory_mb': 1000,  # æœ€å¤§å†…å­˜ä½¿ç”¨é™åˆ¶
    'enable_memory_compression': False,  # å¯ç”¨å†…å­˜å‹ç¼©ï¼ˆå®éªŒæ€§ï¼‰
    'chunk_size_optimization': True,  # å¯ç”¨åˆ†å—å¤§å°ä¼˜åŒ–
}


# ==============================================================================
# 1. é«˜çº§å†…å­˜ç›‘æ§ç±»
# ==============================================================================
class AdvancedMemoryMonitor:
    """é«˜çº§å†…å­˜ç›‘æ§ç±»ï¼Œæä¾›å¤šç§å†…å­˜ç›‘æ§åŠŸèƒ½"""
    
    def __init__(self, enable_tracemalloc: bool = True, log_file: Optional[str] = None, 
                 enable_continuous: bool = False, sampling_interval: float = 1.0, 
                 change_threshold: float = 5.0):
        self.enable_tracemalloc = enable_tracemalloc
        self.log_file = log_file
        self.memory_snapshots: List[Dict] = []
        self.process = psutil.Process()
        self.index_memory_baseline = None  # ç´¢å¼•åŠ è½½å‰çš„å†…å­˜åŸºçº¿
        self.index_file_path = None  # ç´¢å¼•æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºmmapæ£€æµ‹
        self.search_memory_breakdown = []  # æœç´¢æœŸé—´å†…å­˜åˆ†è§£
        self.start_time = time.time()  # è®°å½•ç¨‹åºå¼€å§‹æ—¶é—´
        self.phase_markers = []  # é˜¶æ®µæ ‡è®°ï¼Œå­˜å‚¨(time, phase_name, phase_type)
        
        # è¿ç»­ç›‘æ§ç›¸å…³
        self.enable_continuous = enable_continuous
        self.sampling_interval = sampling_interval
        self.change_threshold = change_threshold
        self.monitoring_thread = None
        self.monitoring_queue = queue.Queue()
        self.stop_monitoring = threading.Event()
        self.last_rss_memory = 0
        self.current_phase = "åˆå§‹åŒ–"
        self.monitoring_active = False
        
        if self.enable_tracemalloc:
            tracemalloc.start()
        
        if self.log_file:
            with open(self.log_file, 'w') as f:
                f.write("æ—¶é—´æˆ³,ç›¸å¯¹æ—¶é—´,é˜¶æ®µ,RSS_MB,å†…å­˜ç™¾åˆ†æ¯”,Pythonå¯¹è±¡æ•°,åƒåœ¾å›æ”¶æ¬¡æ•°,ç´¢å¼•å†…å­˜_MB,å…¶ä»–å†…å­˜_MB,å†…å­˜åˆ†é…æ¥æº,ç›‘æ§ç±»å‹,mmapæ£€æµ‹_MB,mmapæ–¹æ³•,smapsæ£€æµ‹_MB,smapsæ–¹æ³•\n")
        
        # å¯åŠ¨è¿ç»­ç›‘æ§
        if self.enable_continuous:
            self.start_continuous_monitoring()
    
    def get_memory_info(self) -> Dict:
        """è·å–è¯¦ç»†çš„å†…å­˜ä¿¡æ¯"""
        memory_info = self.process.memory_info()
        memory_percent = self.process.memory_percent()
        current_time = time.time()
        
        # è·å–Pythonå¯¹è±¡ç»Ÿè®¡
        gc_stats = gc.get_stats()
        total_objects = sum(stat['collected'] for stat in gc_stats)
        
        # åˆ†æå†…å­˜åˆ†é…æ¥æº
        memory_source = self._analyze_memory_source()
        
        info = {
            'timestamp': current_time,
            'relative_time': current_time - self.start_time,  # ç›¸å¯¹äºç¨‹åºå¼€å§‹çš„æ—¶é—´
            'rss_mb': memory_info.rss / (1024 * 1024),  # å®é™…ç‰©ç†å†…å­˜
            'memory_percent': memory_percent,
            'python_objects': len(gc.get_objects()),
            'gc_collections': total_objects,
            'memory_source': memory_source  # å†…å­˜åˆ†é…æ¥æºåˆ†æ
        }
        
        # å¦‚æœå¯ç”¨äº†tracemallocï¼Œæ·»åŠ æ›´è¯¦ç»†çš„ä¿¡æ¯
        if self.enable_tracemalloc and tracemalloc.is_tracing():
            current, peak = tracemalloc.get_traced_memory()
            info.update({
                'traced_current_mb': current / (1024 * 1024),
                'traced_peak_mb': peak / (1024 * 1024)
            })
        
        # åŸºäºå¤šç§æ–¹æ³•è®¡ç®—ç´¢å¼•å†…å­˜å’Œå…¶ä»–å†…å­˜çš„åˆ†è§£
        if self.index_memory_baseline is not None:
            index_memory = self.estimate_index_memory()
            other_memory = info['rss_mb'] - index_memory
            
            # è·å–è¯¦ç»†çš„mmapæ£€æµ‹ä¿¡æ¯
            mmap_info = self.get_mmap_memory_usage()
            smaps_info = self.get_smaps_memory_usage()
            
            info.update({
                'index_memory_mb': index_memory,
                'other_memory_mb': other_memory,
                'mmap_detection': mmap_info,
                'smaps_detection': smaps_info
            })
        else:
            # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®åŸºçº¿ï¼Œåˆ™æ— æ³•åˆ†è§£å†…å­˜
            info.update({
                'index_memory_mb': 0,
                'other_memory_mb': info['rss_mb'],
                'mmap_detection': {'index_memory_mb': 0, 'method': 'no_baseline'},
                'smaps_detection': {'index_memory_mb': 0, 'method': 'no_baseline'}
            })
        
        return info
    
    def _analyze_memory_source(self) -> str:
        """åŸºäºå®é™…ç›‘æµ‹æ•°æ®åˆ†æå½“å‰å†…å­˜åˆ†é…çš„ä¸»è¦æ¥æº"""
        if self.index_memory_baseline is None:
            return "ç¨‹åºåˆå§‹åŒ–"
        
        current_rss = self.process.memory_info().rss / (1024 * 1024)
        index_memory = self.estimate_index_memory()
        
        # åŸºäºå®é™…ç›‘æµ‹æ•°æ®åˆ¤æ–­å†…å­˜æ¥æº
        if current_rss > 0:
            index_ratio = index_memory / current_rss
            if index_ratio > 0.7:
                return "ç´¢å¼•æ•°æ®"
            elif index_ratio > 0.3:
                return "ç´¢å¼•+å…¶ä»–"
            else:
                return "ç³»ç»Ÿå¼€é”€"
        else:
            return "æœªçŸ¥"
    
    def add_phase_marker(self, phase_name: str, phase_type: str = "é˜¶æ®µ"):
        """æ·»åŠ é˜¶æ®µæ ‡è®°ï¼Œç”¨äºåœ¨å›¾è¡¨ä¸­æ˜¾ç¤º"""
        current_time = time.time()
        self.phase_markers.append({
            'time': current_time,
            'relative_time': current_time - self.start_time,
            'phase_name': phase_name,
            'phase_type': phase_type
        })
    
    def estimate_index_memory(self) -> float:
        """åŸºäºå¤šç§æ–¹æ³•ä¼°ç®—ç´¢å¼•å ç”¨çš„å†…å­˜"""
        if self.index_memory_baseline is None:
            return 0
        
        # æ–¹æ³•1ï¼šä½¿ç”¨mmapå†…å­˜æ˜ å°„æ£€æµ‹ï¼ˆæœ€å‡†ç¡®ï¼‰
        mmap_info = self.get_mmap_memory_usage()
        if mmap_info['method'] == 'memory_maps' and mmap_info['index_memory_mb'] > 0:
            return mmap_info['index_memory_mb']
        
        # æ–¹æ³•2ï¼šä½¿ç”¨smapsæ–‡ä»¶æ£€æµ‹
        smaps_info = self.get_smaps_memory_usage()
        if smaps_info['method'] == 'smaps' and smaps_info['index_memory_mb'] > 0:
            return smaps_info['index_memory_mb']
        
        # æ–¹æ³•3ï¼šå›é€€åˆ°åŸºçº¿å·®å€¼è®¡ç®—
        current_rss = self.process.memory_info().rss / (1024 * 1024)
        index_memory = current_rss - self.index_memory_baseline
        return max(0, index_memory)  # ç¡®ä¿ä¸ä¸ºè´Ÿæ•°
    
    def set_index_memory_baseline(self, baseline_mb: float):
        """è®¾ç½®ç´¢å¼•å†…å­˜åŸºçº¿"""
        self.index_memory_baseline = baseline_mb
        print(f"[å†…å­˜ç›‘æ§] è®¾ç½®ç´¢å¼•å†…å­˜åŸºçº¿: {baseline_mb:.2f} MB")
    
    def set_index_file_path(self, file_path: str):
        """è®¾ç½®ç´¢å¼•æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºmmapå†…å­˜æ£€æµ‹"""
        self.index_file_path = file_path
        print(f"[å†…å­˜ç›‘æ§] è®¾ç½®ç´¢å¼•æ–‡ä»¶è·¯å¾„: {file_path}")
    
    def get_mmap_memory_usage(self) -> Dict:
        """è·å–mmapç´¢å¼•çš„çœŸå®å†…å­˜å ç”¨"""
        if not self.index_file_path:
            return {'index_memory_mb': 0, 'mmap_count': 0, 'method': 'no_file_path'}
        
        try:
            memory_maps = self.process.memory_maps()
            index_memory = 0
            mmap_count = 0
            
            for mmap in memory_maps:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡ç´¢æ–‡ä»¶çš„å†…å­˜æ˜ å°„
                if self.index_file_path in mmap.path:
                    # RSSæ˜¯å®é™…é©»ç•™åœ¨ç‰©ç†å†…å­˜ä¸­çš„å¤§å°
                    index_memory += mmap.rss
                    mmap_count += 1
            
            return {
                'index_memory_mb': index_memory / (1024 * 1024),
                'mmap_count': mmap_count,
                'method': 'memory_maps'
            }
        except Exception as e:
            print(f"[å†…å­˜ç›‘æ§] æ— æ³•è·å–mmapå†…å­˜ä¿¡æ¯: {e}")
            return {'index_memory_mb': 0, 'mmap_count': 0, 'method': 'error'}
    
    def get_smaps_memory_usage(self) -> Dict:
        """é€šè¿‡è§£æ/proc/PID/smapsè·å–æ›´è¯¦ç»†çš„å†…å­˜ä¿¡æ¯"""
        if not self.index_file_path:
            return {'index_memory_mb': 0, 'method': 'no_file_path'}
        
        try:
            with open(f'/proc/{self.process.pid}/smaps', 'r') as f:
                content = f.read()
            
            # æŸ¥æ‰¾åŒ…å«ç´¢å¼•æ–‡ä»¶çš„æ˜ å°„åŒºåŸŸ
            index_memory = 0
            mmap_entries = 0
            
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if self.index_file_path in line and ('r--' in line or 'rw-' in line):
                    mmap_entries += 1
                    # æŸ¥æ‰¾è¯¥æ˜ å°„åŒºåŸŸçš„RSSä¿¡æ¯
                    for j in range(i+1, min(i+20, len(lines))):
                        if 'Rss:' in lines[j]:
                            rss_kb = int(lines[j].split()[1])
                            index_memory += rss_kb
                            break
            
            return {
                'index_memory_mb': index_memory / 1024,
                'mmap_entries': mmap_entries,
                'method': 'smaps'
            }
        except Exception as e:
            print(f"[å†…å­˜ç›‘æ§] æ— æ³•è§£æsmapsæ–‡ä»¶: {e}")
            return {'index_memory_mb': 0, 'method': 'error'}
    
    def analyze_memory_growth_pattern(self) -> Dict:
        """åˆ†æå†…å­˜å¢é•¿æ¨¡å¼"""
        if len(self.memory_snapshots) < 2:
            return {}
        
        analysis = {
            'total_growth_mb': 0,
            'growth_phases': [],
            'peak_usage_mb': 0,
            'memory_efficiency': 0
        }
        
        # è®¡ç®—æ€»å¢é•¿
        first_snapshot = self.memory_snapshots[0]
        last_snapshot = self.memory_snapshots[-1]
        analysis['total_growth_mb'] = last_snapshot['rss_mb'] - first_snapshot['rss_mb']
        analysis['peak_usage_mb'] = max(s['rss_mb'] for s in self.memory_snapshots)
        
        # åˆ†æå„é˜¶æ®µå¢é•¿
        for i in range(1, len(self.memory_snapshots)):
            prev = self.memory_snapshots[i-1]
            curr = self.memory_snapshots[i]
            growth = curr['rss_mb'] - prev['rss_mb']
            analysis['growth_phases'].append({
                'phase': curr.get('phase', f'é˜¶æ®µ{i}'),
                'growth_mb': growth,
                'rss_mb': curr['rss_mb']
            })
        
        return analysis
    
    def start_continuous_monitoring(self):
        """å¯åŠ¨è¿ç»­å†…å­˜ç›‘æ§çº¿ç¨‹"""
        if self.monitoring_active:
            return
            
        self.monitoring_active = True
        self.stop_monitoring.clear()
        self.monitoring_thread = threading.Thread(target=self._continuous_monitoring_worker, daemon=True)
        self.monitoring_thread.start()
        print(f"[è¿ç»­ç›‘æ§] å·²å¯åŠ¨ï¼Œé‡‡æ ·é—´éš”: {self.sampling_interval}ç§’ï¼Œå˜åŒ–é˜ˆå€¼: {self.change_threshold}MB")
    
    def stop_continuous_monitoring(self):
        """åœæ­¢è¿ç»­å†…å­˜ç›‘æ§"""
        if not self.monitoring_active:
            return
            
        self.stop_monitoring.set()
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=2.0)
        self.monitoring_active = False
        print("[è¿ç»­ç›‘æ§] å·²åœæ­¢")
    
    def _continuous_monitoring_worker(self):
        """è¿ç»­ç›‘æ§çš„å·¥ä½œçº¿ç¨‹"""
        while not self.stop_monitoring.is_set():
            try:
                info = self.get_memory_info()
                current_rss = info['rss_mb']
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è®°å½•ï¼ˆå®šæ—¶æˆ–å†…å­˜å˜åŒ–è¶…è¿‡é˜ˆå€¼ï¼‰
                should_record = False
                monitoring_type = "å®šæ—¶é‡‡æ ·"
                
                # å†…å­˜æ˜¾è‘—å˜åŒ–æ—¶ç«‹å³è®°å½•
                if abs(current_rss - self.last_rss_memory) >= self.change_threshold:
                    should_record = True
                    monitoring_type = "å˜åŒ–è§¦å‘"
                    
                # å®šæ—¶é‡‡æ ·
                elif len(self.memory_snapshots) == 0 or \
                     (info['relative_time'] - self.memory_snapshots[-1]['relative_time']) >= self.sampling_interval:
                    should_record = True
                    monitoring_type = "å®šæ—¶é‡‡æ ·"
                
                if should_record:
                    info['phase'] = f"{self.current_phase}_è¿ç»­ç›‘æ§"
                    info['monitoring_type'] = monitoring_type
                    self.memory_snapshots.append(info)
                    self.last_rss_memory = current_rss
                    
                    # å†™å…¥æ—¥å¿—æ–‡ä»¶
                    if self.log_file:
                        with open(self.log_file, 'a') as f:
                            mmap_mb = info.get('mmap_detection', {}).get('index_memory_mb', 0)
                            mmap_method = info.get('mmap_detection', {}).get('method', 'unknown')
                            smaps_mb = info.get('smaps_detection', {}).get('index_memory_mb', 0)
                            smaps_method = info.get('smaps_detection', {}).get('method', 'unknown')
                            f.write(f"{info['timestamp']:.2f},{info['relative_time']:.2f},"
                                   f"{info['phase']},{info['rss_mb']:.2f},{info['memory_percent']:.2f},"
                                   f"{info['python_objects']},{info['gc_collections']},"
                                   f"{info['index_memory_mb']:.2f},{info['other_memory_mb']:.2f},"
                                   f"{info['memory_source']},{monitoring_type},"
                                   f"{mmap_mb:.2f},{mmap_method},{smaps_mb:.2f},{smaps_method}\n")
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡é‡‡æ ·
                self.stop_monitoring.wait(min(self.sampling_interval, 0.5))
                
            except Exception as e:
                print(f"[è¿ç»­ç›‘æ§] é”™è¯¯: {e}")
                break
    
    def set_current_phase(self, phase: str):
        """è®¾ç½®å½“å‰è¿è¡Œé˜¶æ®µ"""
        self.current_phase = phase
        print(f"[é˜¶æ®µåˆ‡æ¢] å½“å‰é˜¶æ®µ: {phase}")
    
    def log_memory_snapshot(self, phase: str, monitoring_type: str = "æ‰‹åŠ¨"):
        """è®°å½•å†…å­˜å¿«ç…§"""
        info = self.get_memory_info()
        info['phase'] = phase
        info['monitoring_type'] = monitoring_type
        self.memory_snapshots.append(info)
        
        # æ›´æ–°å½“å‰é˜¶æ®µ
        if not phase.endswith("_è¿ç»­ç›‘æ§"):
            self.current_phase = phase
        
        # æ·»åŠ é˜¶æ®µæ ‡è®°
        self.add_phase_marker(phase)
        
        if self.log_file:
            with open(self.log_file, 'a') as f:
                mmap_mb = info.get('mmap_detection', {}).get('index_memory_mb', 0)
                mmap_method = info.get('mmap_detection', {}).get('method', 'unknown')
                smaps_mb = info.get('smaps_detection', {}).get('index_memory_mb', 0)
                smaps_method = info.get('smaps_detection', {}).get('method', 'unknown')
                f.write(f"{info['timestamp']:.2f},{info['relative_time']:.2f},{phase},"
                       f"{info['rss_mb']:.2f},{info['memory_percent']:.2f},"
                       f"{info['python_objects']},{info['gc_collections']},"
                       f"{info['index_memory_mb']:.2f},{info['other_memory_mb']:.2f},"
                       f"{info['memory_source']},{monitoring_type},"
                       f"{mmap_mb:.2f},{mmap_method},{smaps_mb:.2f},{smaps_method}\n")
        
        print(f"[å†…å­˜ç›‘æ§] {phase}: RSS={info['rss_mb']:.2f}MB, "
              f"å¯¹è±¡æ•°={info['python_objects']}, "
              f"ç´¢å¼•å†…å­˜={info['index_memory_mb']:.2f}MB, "
              f"å…¶ä»–å†…å­˜={info['other_memory_mb']:.2f}MB, "
              f"æ¥æº={info['memory_source']}")
    
    @contextmanager
    def monitor_phase(self, phase_name: str):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºç›‘æ§ç‰¹å®šä»£ç æ®µçš„å†…å­˜ä½¿ç”¨"""
        print(f"\n[å†…å­˜ç›‘æ§] å¼€å§‹é˜¶æ®µ: {phase_name}")
        
        # è®¾ç½®å½“å‰é˜¶æ®µï¼ˆç”¨äºè¿ç»­ç›‘æ§ï¼‰
        self.set_current_phase(phase_name)
        self.log_memory_snapshot(f"{phase_name}_å¼€å§‹")
        
        start_info = self.get_memory_info()
        start_time = time.time()
        
        try:
            yield
        finally:
            end_time = time.time()
            end_info = self.get_memory_info()
            
            # è®¡ç®—å†…å­˜å˜åŒ–
            rss_diff = end_info['rss_mb'] - start_info['rss_mb']
            objects_diff = end_info['python_objects'] - start_info['python_objects']
            
            print(f"[å†…å­˜ç›‘æ§] ç»“æŸé˜¶æ®µ: {phase_name}")
            print(f"  è€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"  RSSå˜åŒ–: {rss_diff:+.2f}MB")
            print(f"  Pythonå¯¹è±¡å˜åŒ–: {objects_diff:+d}")
            print(f"  å†…å­˜æ¥æºå˜åŒ–: {start_info['memory_source']} -> {end_info['memory_source']}")
            
            self.log_memory_snapshot(f"{phase_name}_ç»“æŸ")
    
    def get_memory_summary(self) -> Dict:
        """è·å–å†…å­˜ä½¿ç”¨æ‘˜è¦"""
        if not self.memory_snapshots:
            return {}
        
        rss_values = [s['rss_mb'] for s in self.memory_snapshots]
        
        return {
            'peak_rss_mb': max(rss_values),
            'avg_rss_mb': sum(rss_values) / len(rss_values),
            'total_snapshots': len(self.memory_snapshots),
            'total_duration': self.memory_snapshots[-1]['relative_time'] if self.memory_snapshots else 0
        }
    
    def force_gc_and_log(self, phase: str):
        """å¼ºåˆ¶åƒåœ¾å›æ”¶å¹¶è®°å½•å†…å­˜å˜åŒ–"""
        before_info = self.get_memory_info()
        gc.collect()
        after_info = self.get_memory_info()
        
        rss_freed = before_info['rss_mb'] - after_info['rss_mb']
        objects_freed = before_info['python_objects'] - after_info['python_objects']
        
        print(f"[åƒåœ¾å›æ”¶] {phase}: é‡Šæ”¾RSS={rss_freed:.2f}MB, å¯¹è±¡={objects_freed}")
        self.log_memory_snapshot(f"{phase}_GCå")
    
    def get_tracemalloc_top_stats(self, limit: int = 10):
        """è·å–tracemallocç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        if not self.enable_tracemalloc or not tracemalloc.is_tracing():
            return None
        
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')
        
        print(f"\n[å†…å­˜åˆ†æ] Top {limit} å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ:")
        for index, stat in enumerate(top_stats[:limit], 1):
            print(f"{index}. {stat}")
        
        return top_stats[:limit]
    
    def get_memory_optimization_suggestions(self) -> List[str]:
        """åŸºäºå®é™…ç›‘æµ‹æ•°æ®è·å–å†…å­˜ä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        if not self.memory_snapshots:
            return suggestions
        
        # åˆ†æå†…å­˜å¢é•¿æ¨¡å¼
        analysis = self.analyze_memory_growth_pattern()
        
        # åŸºäºå®é™…ç›‘æµ‹æ•°æ®åˆ¤æ–­å†…å­˜å¢é•¿
        total_growth = analysis.get('total_growth_mb', 0)
        if total_growth > 500:  # å¦‚æœæ€»å¢é•¿è¶…è¿‡500MB
            suggestions.append("âš ï¸  å†…å­˜å¢é•¿è¾ƒå¤§ï¼Œå»ºè®®åœ¨æœç´¢å‰è¿›è¡Œåƒåœ¾å›æ”¶")
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æ•ˆç‡
        last_snapshot = self.memory_snapshots[-1]
        
        # æ£€æŸ¥Pythonå¯¹è±¡æ•°é‡ï¼ˆåŸºäºå®é™…ç›‘æµ‹æ•°æ®ï¼‰
        if last_snapshot['python_objects'] > 100000:
            suggestions.append("âš ï¸  Pythonå¯¹è±¡æ•°é‡è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰å¯¹è±¡æ³„æ¼")
        
        # åŸºäºå®é™…ç›‘æµ‹æ•°æ®æ£€æŸ¥ç´¢å¼•å†…å­˜å æ¯”
        if last_snapshot.get('index_memory_mb', 0) > 0 and last_snapshot['rss_mb'] > 0:
            index_ratio = last_snapshot['index_memory_mb'] / last_snapshot['rss_mb']
            if index_ratio < 0.3:  # ç´¢å¼•å†…å­˜å æ¯”å°äº30%
                suggestions.append("ğŸ’¡ ç´¢å¼•å†…å­˜å æ¯”è¾ƒä½ï¼Œå…¶ä»–å†…å­˜ä½¿ç”¨å¯èƒ½è¿‡å¤š")
            elif index_ratio > 0.8:  # ç´¢å¼•å†…å­˜å æ¯”å¤§äº80%
                suggestions.append("ğŸ’¡ ç´¢å¼•å†…å­˜å æ¯”å¾ˆé«˜ï¼Œè¿™æ˜¯æ­£å¸¸çš„")
        
        return suggestions
    
    def generate_memory_visualization(self, output_file: str):
        """ç”Ÿæˆå†…å­˜ä½¿ç”¨å¯è§†åŒ–å›¾è¡¨"""
        if not self.memory_snapshots:
            print("æ²¡æœ‰å†…å­˜å¿«ç…§æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
            return
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦‚æœæ²¡æœ‰ä¸­æ–‡å­—ä½“åˆ™ä½¿ç”¨è‹±æ–‡
        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'WenQuanYi Zen Hei', 'SimHei', 'sans-serif']
        plt.rcParams['font.monospace'] = ['Noto Sans CJK SC', 'WenQuanYi Zen Hei', 'SimHei', 'monospace']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
        fig.suptitle('Memory Usage Analysis', fontsize=16, fontweight='bold')
        
        # å‡†å¤‡æ•°æ®
        times = [s['relative_time'] for s in self.memory_snapshots]
        rss_values = [s['rss_mb'] for s in self.memory_snapshots]
        index_memory = [s['index_memory_mb'] for s in self.memory_snapshots]
        other_memory = [s['other_memory_mb'] for s in self.memory_snapshots]
        phases = [s['phase'] for s in self.memory_snapshots]
        
        # ç¬¬ä¸€ä¸ªå­å›¾ï¼šæ€»ä½“å†…å­˜ä½¿ç”¨
        ax1.plot(times, rss_values, 'b-', linewidth=2, label='Total Physical Memory (RSS)', alpha=0.8)
        ax1.fill_between(times, rss_values, alpha=0.3, color='blue')
        
        # æ·»åŠ é˜¶æ®µåˆ†åŒº
        self._add_phase_sections(ax1, times, max(rss_values))
        
        ax1.set_xlabel('Runtime (seconds)')
        ax1.set_ylabel('Memory Usage (MB)')
        ax1.set_title('Overall Memory Usage Trend')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # ç¬¬äºŒä¸ªå­å›¾ï¼šå†…å­˜åˆ†è§£
        ax2.stackplot(times, index_memory, other_memory, 
                     labels=['Index Memory', 'Other Memory'],
                     colors=['#ff9999', '#66b3ff'], alpha=0.8)
        
        # æ·»åŠ é˜¶æ®µåˆ†åŒº
        self._add_phase_sections(ax2, times, max(rss_values))
        
        ax2.set_xlabel('Runtime (seconds)')
        ax2.set_ylabel('Memory Usage (MB)')
        ax2.set_title('Memory Usage Breakdown (Index vs Other)')
        ax2.grid(True, alpha=0.3)
        ax2.legend(loc='upper left')
        
        # æ·»åŠ å†…å­˜å ç”¨åˆ†ææ³¨é‡Š
        self._add_memory_annotations(ax1, times, rss_values, phases)
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"å†…å­˜ä½¿ç”¨å›¾è¡¨å·²ä¿å­˜åˆ°: {output_file}")
    
    def generate_final_memory_plot(self, output_file: str):
        """ç”Ÿæˆæœ€ç»ˆçš„å†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨ï¼ˆä»…RSSå†…å­˜ï¼ŒæŒ‰è¿è¡Œé˜¶æ®µåˆ†æï¼‰"""
        if not self.memory_snapshots:
            print("æ²¡æœ‰å†…å­˜å¿«ç…§æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæœ€ç»ˆå†…å­˜å›¾è¡¨")
            return
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'WenQuanYi Zen Hei', 'SimHei', 'sans-serif']
        plt.rcParams['font.monospace'] = ['Noto Sans CJK SC', 'WenQuanYi Zen Hei', 'SimHei', 'monospace']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºå¤šå­å›¾å¸ƒå±€ï¼šé˜¶æ®µæ—¶é—´çº¿ + å†…å­˜å›¾è¡¨ + é˜¶æ®µè¯¦æƒ…
        fig = plt.figure(figsize=(18, 12))
        gs = fig.add_gridspec(4, 1, height_ratios=[0.8, 3, 0.8, 1.2], hspace=0.3)
        
        # å‡†å¤‡æ•°æ®
        times = [s['relative_time'] for s in self.memory_snapshots]
        rss_values = [s['rss_mb'] for s in self.memory_snapshots]
        index_memory = [s['index_memory_mb'] for s in self.memory_snapshots]
        other_memory = [s['other_memory_mb'] for s in self.memory_snapshots]
        phases = [s['phase'] for s in self.memory_snapshots]
        memory_sources = [s.get('memory_source', 'æœªçŸ¥') for s in self.memory_snapshots]
        
        # è¯†åˆ«ä¸»è¦é˜¶æ®µ
        phase_boundaries = self._identify_main_phases(phases, times)
        phase_info = self._get_comprehensive_phase_info(phase_boundaries, times, rss_values)
        
        # 1. ä¸Šæ–¹ï¼šé˜¶æ®µæ—¶é—´çº¿
        ax_timeline = fig.add_subplot(gs[0])
        self._draw_phase_timeline(ax_timeline, phase_info, times)
        
        # 2. ä¸­é—´ï¼šä¸»è¦å†…å­˜å›¾è¡¨
        ax_main = fig.add_subplot(gs[1])
        self._draw_main_memory_chart(ax_main, times, rss_values, index_memory, other_memory, phase_info)
        
        # 3. ä¸‹æ–¹ï¼šé˜¶æ®µå†…å­˜æ¡å½¢å›¾
        ax_phases = fig.add_subplot(gs[2])
        self._draw_phase_memory_bars(ax_phases, phase_info)
        
        # 4. åº•éƒ¨ï¼šè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        ax_stats = fig.add_subplot(gs[3])
        self._draw_detailed_statistics(ax_stats, phase_info, times, rss_values, index_memory, other_memory)
        
        # è®¾ç½®æ•´ä½“æ ‡é¢˜
        fig.suptitle('Faissç¨‹åºè¿è¡Œå†…å­˜ä½¿ç”¨æƒ…å†µè¯¦ç»†åˆ†æ', fontsize=20, fontweight='bold', y=0.95)
        
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"æœ€ç»ˆå†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨å·²ä¿å­˜åˆ°: {output_file}")
        plt.close()
    
    def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œåœæ­¢ç›‘æ§çº¿ç¨‹"""
        if self.enable_continuous:
            self.stop_continuous_monitoring()
        
        if self.enable_tracemalloc and tracemalloc.is_tracing():
            tracemalloc.stop()
    
    def get_monitoring_statistics(self) -> Dict:
        """è·å–ç›‘æ§ç»Ÿè®¡ä¿¡æ¯"""
        if not self.memory_snapshots:
            return {}
        
        # åˆ†ç±»ç»Ÿè®¡ä¸åŒç±»å‹çš„ç›‘æ§è®°å½•
        manual_records = [s for s in self.memory_snapshots if s.get('monitoring_type', 'æ‰‹åŠ¨') == 'æ‰‹åŠ¨']
        timed_records = [s for s in self.memory_snapshots if s.get('monitoring_type', '') == 'å®šæ—¶é‡‡æ ·']
        change_triggered_records = [s for s in self.memory_snapshots if s.get('monitoring_type', '') == 'å˜åŒ–è§¦å‘']
        
        return {
            'total_snapshots': len(self.memory_snapshots),
            'manual_snapshots': len(manual_records),
            'timed_snapshots': len(timed_records),
            'change_triggered_snapshots': len(change_triggered_records),
            'monitoring_duration': self.memory_snapshots[-1]['relative_time'] - self.memory_snapshots[0]['relative_time'] if self.memory_snapshots else 0,
            'average_sampling_rate': len(self.memory_snapshots) / (self.memory_snapshots[-1]['relative_time'] - self.memory_snapshots[0]['relative_time']) if len(self.memory_snapshots) > 1 else 0
        }
    
    def _identify_main_phases(self, phases, times):
        """è¯†åˆ«ä¸»è¦çš„è¿è¡Œé˜¶æ®µï¼ˆè®­ç»ƒã€æ„å»ºã€æœç´¢ï¼‰"""
        boundaries = []
        current_phase = None
        
        for i, phase in enumerate(phases):
            phase_lower = phase.lower()
            
            # è®­ç»ƒé˜¶æ®µ
            if ('è®­ç»ƒ' in phase or 'train' in phase_lower or 'é‡åŒ–å™¨' in phase) and current_phase != 'training':
                boundaries.append(('training', i, times[i] if i < len(times) else 0, 'è®­ç»ƒé˜¶æ®µ'))
                current_phase = 'training'
            
            # æ„å»ºé˜¶æ®µï¼ˆåŒ…æ‹¬æ·»åŠ æ•°æ®ï¼‰
            elif ('æ„å»º' in phase or 'æ·»åŠ ' in phase or 'build' in phase_lower or 'add' in phase_lower or 'å¤„ç†å—' in phase) and current_phase != 'building':
                boundaries.append(('building', i, times[i] if i < len(times) else 0, 'æ„å»ºé˜¶æ®µ'))
                current_phase = 'building'
            
            # æœç´¢é˜¶æ®µ
            elif ('æœç´¢' in phase or 'search' in phase_lower or 'æŸ¥è¯¢' in phase) and current_phase != 'searching':
                boundaries.append(('searching', i, times[i] if i < len(times) else 0, 'æœç´¢é˜¶æ®µ'))
                current_phase = 'searching'
                
            # è¯„ä¼°é˜¶æ®µ
            elif ('å¬å›' in phase or 'è®¡ç®—' in phase or 'recall' in phase_lower or 'evaluation' in phase_lower) and current_phase != 'evaluation':
                boundaries.append(('evaluation', i, times[i] if i < len(times) else 0, 'è¯„ä¼°é˜¶æ®µ'))
                current_phase = 'evaluation'
        
        return boundaries
    
    def _get_comprehensive_phase_info(self, phase_boundaries, times, rss_values):
        """è·å–å®Œæ•´çš„é˜¶æ®µä¿¡æ¯"""
        if not phase_boundaries:
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°é˜¶æ®µï¼Œåˆ›å»ºé»˜è®¤çš„"å…¶ä»–"é˜¶æ®µ
            return [{
                'type': 'other',
                'name': 'å…¶ä»–é˜¶æ®µ',
                'start_time': 0,
                'end_time': times[-1] if times else 1,
                'duration': times[-1] if times else 1,
                'start_memory': rss_values[0] if rss_values else 0,
                'end_memory': rss_values[-1] if rss_values else 0,
                'peak_memory': max(rss_values) if rss_values else 0,
                'memory_growth': (rss_values[-1] - rss_values[0]) if rss_values else 0,
                'color': '#ffcccc'
            }]
        
        phase_info = []
        total_time = times[-1] if times else 1
        
        for i, (phase_type, idx, time_point, label) in enumerate(phase_boundaries):
            # è®¡ç®—é˜¶æ®µæ—¶é—´èŒƒå›´
            start_time = time_point
            if i + 1 < len(phase_boundaries):
                end_time = phase_boundaries[i + 1][2]
            else:
                end_time = total_time
            
            # æ‰¾åˆ°è¯¥é˜¶æ®µçš„å†…å­˜æ•°æ®
            start_idx = idx
            end_idx = phase_boundaries[i + 1][1] if i + 1 < len(phase_boundaries) else len(rss_values) - 1
            
            phase_rss_values = rss_values[start_idx:end_idx + 1]
            start_memory = rss_values[start_idx] if start_idx < len(rss_values) else 0
            end_memory = rss_values[end_idx] if end_idx < len(rss_values) else start_memory
            peak_memory = max(phase_rss_values) if phase_rss_values else start_memory
            
            # å®šä¹‰é˜¶æ®µé¢œè‰²
            colors = {
                'training': '#87CEEB',    # å¤©è“è‰²
                'building': '#98FB98',    # æ·¡ç»¿è‰²  
                'searching': '#FFE4B5',   # æµ…é»„è‰²
                'evaluation': '#FFA07A',  # æµ…æ©™è‰²
                'other': '#E6E6FA'        # æ·¡ç´«è‰²
            }
            
            phase_info.append({
                'type': phase_type,
                'name': label,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time,
                'start_memory': start_memory,
                'end_memory': end_memory,
                'peak_memory': peak_memory,
                'memory_growth': end_memory - start_memory,
                'color': colors.get(phase_type, '#E6E6FA')
            })
        
        return phase_info
    
    def _draw_phase_timeline(self, ax, phase_info, times):
        """ç»˜åˆ¶é˜¶æ®µæ—¶é—´çº¿"""
        ax.set_xlim(0, times[-1] if times else 1)
        ax.set_ylim(-0.5, 0.5)
        
        # ç»˜åˆ¶æ—¶é—´çº¿
        ax.axhline(y=0, color='black', linewidth=2, alpha=0.8)
        
        # ç»˜åˆ¶æ¯ä¸ªé˜¶æ®µ
        for phase in phase_info:
            # ç»˜åˆ¶é˜¶æ®µåŒºé—´
            ax.barh(0, phase['duration'], left=phase['start_time'], height=0.3, 
                   color=phase['color'], alpha=0.8, edgecolor='black', linewidth=1)
            
            # æ·»åŠ é˜¶æ®µåç§°
            mid_time = phase['start_time'] + phase['duration'] / 2
            ax.text(mid_time, 0, phase['name'], ha='center', va='center', 
                   fontsize=12, fontweight='bold', color='black')
            
            # æ·»åŠ æ—¶é—´èŒƒå›´æ ‡æ³¨
            ax.text(mid_time, -0.35, f"{phase['duration']:.1f}s", 
                   ha='center', va='center', fontsize=10, style='italic')
        
        ax.set_ylabel('è¿è¡Œé˜¶æ®µ', fontsize=12)
        ax.set_title('ç¨‹åºè¿è¡Œé˜¶æ®µæ—¶é—´çº¿', fontsize=14, fontweight='bold', pad=20)
        ax.set_yticks([])
        ax.grid(True, alpha=0.3, axis='x')
        
        # éšè—xè½´æ ‡ç­¾ï¼ˆåœ¨ä¸»å›¾ä¸­æ˜¾ç¤ºï¼‰
        ax.set_xticklabels([])
    
    def _draw_main_memory_chart(self, ax, times, rss_values, index_memory, other_memory, phase_info):
        """ç»˜åˆ¶ä¸»è¦çš„å†…å­˜ä½¿ç”¨å›¾è¡¨"""
        # ç»˜åˆ¶é˜¶æ®µèƒŒæ™¯
        for phase in phase_info:
            ax.axvspan(phase['start_time'], phase['end_time'], 
                      alpha=0.15, color=phase['color'], zorder=0)
        
        # ç»˜åˆ¶å†…å­˜åˆ†è§£çš„å †å åŒºåŸŸå›¾
        ax.fill_between(times, 0, index_memory, alpha=0.7, color='#2E8B57', label='ç´¢å¼•å†…å­˜')
        ax.fill_between(times, index_memory, 
                       [idx + other for idx, other in zip(index_memory, other_memory)], 
                       alpha=0.7, color='#FF6347', label='å…¶ä»–å†…å­˜')
        
        # ç»˜åˆ¶æ€»å†…å­˜æ›²çº¿
        ax.plot(times, rss_values, 'b-', linewidth=3, label='æ€»ç‰©ç†å†…å­˜(RSS)', 
               marker='o', markersize=3, alpha=0.9, zorder=5)
        
        # æ·»åŠ é˜¶æ®µåˆ†éš”çº¿
        for i, phase in enumerate(phase_info[:-1]):  # æœ€åä¸€ä¸ªé˜¶æ®µä¸éœ€è¦åˆ†éš”çº¿
            ax.axvline(x=phase['end_time'], color='red', linestyle='--', 
                      linewidth=2, alpha=0.8, zorder=3)
        
        # æ ‡æ³¨æ¯ä¸ªé˜¶æ®µçš„å³°å€¼å†…å­˜
        for phase in phase_info:
            peak_time = phase['start_time'] + phase['duration'] / 2
            peak_memory = phase['peak_memory']
            
            ax.annotate(f'{phase["name"]}\nå³°å€¼: {peak_memory:.0f}MB\nå¢é•¿: {phase["memory_growth"]:+.0f}MB', 
                       xy=(peak_time, peak_memory), 
                       xytext=(peak_time, peak_memory + max(rss_values) * 0.15),
                       arrowprops=dict(arrowstyle='->', color='darkred', lw=1.5),
                       fontsize=10, ha='center', va='bottom', fontweight='bold',
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="white", 
                                alpha=0.9, edgecolor=phase['color'], linewidth=2))
        
        ax.set_xlabel('è¿è¡Œæ—¶é—´ (ç§’)', fontsize=14)
        ax.set_ylabel('å†…å­˜ä½¿ç”¨é‡ (MB)', fontsize=14)
        ax.set_title('å†…å­˜ä½¿ç”¨è¯¦ç»†åˆ†æ - æŒ‰é˜¶æ®µåˆ’åˆ†', fontsize=16, fontweight='bold')
        ax.legend(fontsize=12, loc='upper left')
        ax.grid(True, alpha=0.3)
    
    def _draw_phase_memory_bars(self, ax, phase_info):
        """ç»˜åˆ¶é˜¶æ®µå†…å­˜ä½¿ç”¨æ¡å½¢å›¾"""
        phase_names = [phase['name'] for phase in phase_info]
        start_memories = [phase['start_memory'] for phase in phase_info]
        end_memories = [phase['end_memory'] for phase in phase_info]
        peak_memories = [phase['peak_memory'] for phase in phase_info]
        colors = [phase['color'] for phase in phase_info]
        
        x = range(len(phase_names))
        width = 0.25
        
        # ç»˜åˆ¶æ¡å½¢å›¾
        bars1 = ax.bar([i - width for i in x], start_memories, width, 
                      label='å¼€å§‹å†…å­˜', color=[c for c in colors], alpha=0.6)
        bars2 = ax.bar([i for i in x], peak_memories, width, 
                      label='å³°å€¼å†…å­˜', color=[c for c in colors], alpha=0.9)
        bars3 = ax.bar([i + width for i in x], end_memories, width, 
                      label='ç»“æŸå†…å­˜', color=[c for c in colors], alpha=0.7)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (start, peak, end) in enumerate(zip(start_memories, peak_memories, end_memories)):
            ax.text(i - width, start + max(peak_memories) * 0.02, f'{start:.0f}', 
                   ha='center', va='bottom', fontsize=9)
            ax.text(i, peak + max(peak_memories) * 0.02, f'{peak:.0f}', 
                   ha='center', va='bottom', fontsize=9, fontweight='bold')
            ax.text(i + width, end + max(peak_memories) * 0.02, f'{end:.0f}', 
                   ha='center', va='bottom', fontsize=9)
        
        ax.set_ylabel('å†…å­˜ä½¿ç”¨é‡ (MB)', fontsize=12)
        ax.set_title('å„é˜¶æ®µå†…å­˜ä½¿ç”¨å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(phase_names, rotation=0, ha='center')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3, axis='y')
    
    def _draw_detailed_statistics(self, ax, phase_info, times, rss_values, index_memory, other_memory):
        """ç»˜åˆ¶è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        ax.axis('off')  # éšè—åæ ‡è½´
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        total_duration = times[-1] if times else 0
        total_growth = rss_values[-1] - rss_values[0] if rss_values else 0
        peak_memory = max(rss_values) if rss_values else 0
        final_index_memory = index_memory[-1] if index_memory else 0
        final_other_memory = other_memory[-1] if other_memory else 0
        
        # åˆ›å»ºç»Ÿè®¡æ–‡æœ¬
        stats_text = f"""ç¨‹åºè¿è¡Œæ€»ä½“ç»Ÿè®¡:
â€¢ æ€»è¿è¡Œæ—¶é—´: {total_duration:.1f} ç§’
â€¢ æ€»å†…å­˜å¢é•¿: {total_growth:.1f} MB
â€¢ å³°å€¼å†…å­˜: {peak_memory:.1f} MB
â€¢ æœ€ç»ˆå†…å­˜æ„æˆ: ç´¢å¼• {final_index_memory:.1f} MB ({final_index_memory/(final_index_memory+final_other_memory)*100:.1f}%) + å…¶ä»– {final_other_memory:.1f} MB ({final_other_memory/(final_index_memory+final_other_memory)*100:.1f}%)

å„é˜¶æ®µè¯¦ç»†åˆ†æ:"""
        
        for phase in phase_info:
            stats_text += f"""
â€¢ {phase['name']}: {phase['duration']:.1f}s, å†…å­˜ä» {phase['start_memory']:.1f}MB åˆ° {phase['end_memory']:.1f}MB (å³°å€¼: {phase['peak_memory']:.1f}MB)"""
        
        # æ˜¾ç¤ºç»Ÿè®¡æ–‡æœ¬
        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=11,
               verticalalignment='top', horizontalalignment='left',
               bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.9),
               family='monospace')
    
    def _add_phase_backgrounds_final(self, ax, phase_boundaries, times, max_value):
        """æ·»åŠ é˜¶æ®µèƒŒæ™¯è‰²å’Œåˆ†éš”çº¿"""
        if not phase_boundaries:
            return
            
        # å®šä¹‰é˜¶æ®µé¢œè‰²
        phase_colors = {
            'training': 'lightblue',
            'building': 'lightgreen', 
            'searching': 'lightyellow',
            'evaluation': 'lightcoral'
        }
        
        # æ·»åŠ èƒŒæ™¯è‰²
        for i, (phase_type, idx, time_point, label) in enumerate(phase_boundaries):
            # è®¡ç®—é˜¶æ®µçš„æ—¶é—´èŒƒå›´
            start_time = time_point
            if i + 1 < len(phase_boundaries):
                end_time = phase_boundaries[i + 1][2]
            else:
                end_time = times[-1] if times else start_time + 1
                
            # æ·»åŠ èƒŒæ™¯è‰²
            ax.axvspan(start_time, end_time, alpha=0.2, color=phase_colors.get(phase_type, 'lightgray'))
            
            # æ·»åŠ åˆ†éš”çº¿
            ax.axvline(x=start_time, color='red', linestyle='--', alpha=0.8, linewidth=2)
            
            # æ·»åŠ é˜¶æ®µæ ‡ç­¾
            label_x = start_time + (end_time - start_time) / 2
            ax.text(label_x, max_value * 0.95, label, ha='center', va='top', 
                   fontsize=12, fontweight='bold', 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor=phase_colors.get(phase_type, 'lightgray'), alpha=0.8))
    
    def _add_memory_growth_annotations_final(self, ax, times, rss_values, phases, memory_sources):
        """æ·»åŠ å†…å­˜å¢é•¿å…³é”®ç‚¹çš„æ ‡æ³¨"""
        if len(rss_values) < 2:
            return
            
        # æ‰¾åˆ°å†…å­˜æ˜¾è‘—å¢é•¿çš„ç‚¹
        growth_points = []
        for i in range(1, len(rss_values)):
            growth = rss_values[i] - rss_values[i-1]
            if growth > 50:  # å¢é•¿è¶…è¿‡50MBçš„ç‚¹
                growth_points.append((i, growth, times[i], rss_values[i], phases[i], memory_sources[i]))
        
        # æ ‡æ³¨æ˜¾è‘—å¢é•¿ç‚¹
        for idx, growth, time_point, memory_value, phase, source in growth_points[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªç‚¹
            ax.annotate(f'+{growth:.0f}MB\n{phase}\nåŸå› : {source}', 
                       xy=(time_point, memory_value), 
                       xytext=(time_point + max(times) * 0.05, memory_value + max(rss_values) * 0.05),
                       arrowprops=dict(arrowstyle='->', color='red', lw=1.5),
                       fontsize=9, ha='left', va='bottom',
                       bbox=dict(boxstyle="round,pad=0.2", facecolor="yellow", alpha=0.7))
        
        # æ ‡æ³¨å³°å€¼å†…å­˜ç‚¹
        peak_idx = rss_values.index(max(rss_values))
        peak_time = times[peak_idx]
        peak_memory = rss_values[peak_idx]
        ax.annotate(f'å³°å€¼å†…å­˜: {peak_memory:.1f}MB\né˜¶æ®µ: {phases[peak_idx]}\næ¥æº: {memory_sources[peak_idx]}', 
                   xy=(peak_time, peak_memory), 
                   xytext=(peak_time + max(times)*0.1, peak_memory + max(rss_values)*0.1),
                   arrowprops=dict(arrowstyle='->', color='darkred', lw=2),
                   fontsize=10, color='darkred', fontweight='bold',
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.9, edgecolor='red'))
    
    def _add_detailed_memory_analysis_final(self, fig, rss_values, index_memory, other_memory, phase_boundaries, times):
        """æ·»åŠ è¯¦ç»†çš„å†…å­˜åˆ†æä¿¡æ¯"""
        if not rss_values:
            return
            
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        peak_rss = max(rss_values)
        final_rss = rss_values[-1]
        total_growth = final_rss - rss_values[0]
        final_index_memory = index_memory[-1] if index_memory else 0
        final_other_memory = other_memory[-1] if other_memory else 0
        
        # è®¡ç®—å„é˜¶æ®µçš„å†…å­˜ä½¿ç”¨
        phase_memory_info = []
        for i, (phase_type, idx, time_point, label) in enumerate(phase_boundaries):
            if idx < len(rss_values):
                phase_memory = rss_values[idx]
                phase_memory_info.append(f"{label}: {phase_memory:.1f}MB")
        
        # åŸºäºå®é™…ç›‘æµ‹æ•°æ®è®¡ç®—å†…å­˜æ•ˆç‡æŒ‡æ ‡
        memory_efficiency = final_index_memory / final_rss if final_rss > 0 else 0
        growth_rate = total_growth / peak_rss if peak_rss > 0 else 0
        
        # åˆ›å»ºåˆ†ææ–‡æœ¬
        analysis_text = f"""å†…å­˜ä½¿ç”¨è¯¦ç»†åˆ†æ:

å³°å€¼å†…å­˜: {peak_rss:.1f} MB
æ€»å†…å­˜å¢é•¿: {total_growth:.1f} MB  
æœ€ç»ˆå†…å­˜: {final_rss:.1f} MB

å†…å­˜æ„æˆåˆ†æ:
â€¢ ç´¢å¼•å†…å­˜: {final_index_memory:.1f} MB ({memory_efficiency*100:.1f}%)
â€¢ å…¶ä»–å†…å­˜: {final_other_memory:.1f} MB ({(1-memory_efficiency)*100:.1f}%)

å„é˜¶æ®µå†…å­˜:
{chr(10).join(phase_memory_info)}

å†…å­˜æ•ˆç‡è¯„ä¼°:
â€¢ å†…å­˜åˆ©ç”¨ç‡: {'è‰¯å¥½' if memory_efficiency > 0.5 else 'å¯ä¼˜åŒ–'}
â€¢ å†…å­˜å¢é•¿: {'å¹³ç¨³' if growth_rate < 0.5 else 'è¾ƒå¤§'}
â€¢ æ€»è¿è¡Œæ—¶é—´: {times[-1]:.1f}ç§’"""

        # æ·»åŠ åˆ†ææ–‡æœ¬æ¡†
        fig.text(0.02, 0.02, analysis_text, fontsize=11,
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.9),
                verticalalignment='bottom', horizontalalignment='left')
    
    def _add_phase_sections(self, ax, times, max_value):
        """åœ¨å›¾è¡¨ä¸­æ·»åŠ é˜¶æ®µåˆ†åŒº"""
        if not self.phase_markers:
            return
        
        # å®šä¹‰é˜¶æ®µå’Œå¯¹åº”çš„é¢œè‰²
        phase_colors = {
            'Training': '#ffcccc',
            'Building': '#ccffcc',
            'Search': '#ccccff',
            'Other': '#ffffcc'
        }
        
        # æ ¹æ®é˜¶æ®µåç§°åˆ¤æ–­é˜¶æ®µç±»å‹
        current_phase = None
        phase_start = 0
        
        for i, marker in enumerate(self.phase_markers):
            phase_name = marker['phase_name']
            time_point = marker['relative_time']
            
            # åˆ¤æ–­é˜¶æ®µç±»å‹
            if 'è®­ç»ƒ' in phase_name:
                new_phase = 'Training'
            elif 'æ„å»º' in phase_name or 'æ·»åŠ ' in phase_name:
                new_phase = 'Building'
            elif 'æœç´¢' in phase_name:
                new_phase = 'Search'
            else:
                new_phase = 'Other'
            
            # å¦‚æœé˜¶æ®µæ”¹å˜ï¼Œç»˜åˆ¶å‰ä¸€ä¸ªé˜¶æ®µçš„èƒŒæ™¯
            if current_phase and new_phase != current_phase:
                color = phase_colors.get(current_phase, '#ffffcc')
                ax.axvspan(phase_start, time_point, alpha=0.2, color=color, 
                          label=f'{current_phase} Phase')
            
            if new_phase != current_phase:
                current_phase = new_phase
                phase_start = time_point
        
        # ç»˜åˆ¶æœ€åä¸€ä¸ªé˜¶æ®µ
        if current_phase and times:
            color = phase_colors.get(current_phase, '#ffffcc')
            ax.axvspan(phase_start, max(times), alpha=0.2, color=color,
                      label=f'{current_phase}é˜¶æ®µ')
    
    def _add_memory_annotations(self, ax, times, rss_values, phases):
        """æ·»åŠ å†…å­˜å ç”¨åˆ†ææ³¨é‡Š"""
        if not times or not rss_values:
            return
        
        # æ‰¾åˆ°å³°å€¼å†…å­˜ç‚¹
        peak_idx = rss_values.index(max(rss_values))
        peak_time = times[peak_idx]
        peak_memory = rss_values[peak_idx]
        
        # æ·»åŠ å³°å€¼æ³¨é‡Š
        ax.annotate(f'å³°å€¼: {peak_memory:.1f}MB\\né˜¶æ®µ: {phases[peak_idx]}', 
                   xy=(peak_time, peak_memory), 
                   xytext=(peak_time + max(times)*0.1, peak_memory + max(rss_values)*0.1),
                   arrowprops=dict(arrowstyle='->', color='red'),
                   fontsize=10, color='red',
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # æ·»åŠ å†…å­˜å¢é•¿æœ€å¿«çš„ç‚¹
        if len(rss_values) > 1:
            growth_rates = [rss_values[i] - rss_values[i-1] for i in range(1, len(rss_values))]
            if growth_rates:
                max_growth_idx = growth_rates.index(max(growth_rates)) + 1
                max_growth_time = times[max_growth_idx]
                max_growth_memory = rss_values[max_growth_idx]
                
                ax.annotate(f'æœ€å¤§å¢é•¿: +{max(growth_rates):.1f}MB\\né˜¶æ®µ: {phases[max_growth_idx]}', 
                           xy=(max_growth_time, max_growth_memory), 
                           xytext=(max_growth_time - max(times)*0.15, max_growth_memory),
                           arrowprops=dict(arrowstyle='->', color='orange'),
                           fontsize=10, color='orange',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

# åˆ›å»ºå…¨å±€å†…å­˜ç›‘æ§å™¨
memory_monitor = AdvancedMemoryMonitor(
    enable_tracemalloc=ENABLE_DETAILED_MEMORY_MONITORING,
    log_file=MEMORY_LOG_FILENAME if ENABLE_DETAILED_MEMORY_MONITORING else None,
    enable_continuous=ENABLE_CONTINUOUS_MONITORING,
    sampling_interval=MEMORY_SAMPLING_INTERVAL,
    change_threshold=MEMORY_CHANGE_THRESHOLD
)

# ==============================================================================
# 2. è¾…åŠ©å‡½æ•°ï¼šè¯»å–.fbinæ–‡ä»¶
# ==============================================================================
def read_fbin(filename, start_idx=0, chunk_size=None):
    """
    è¯»å–.fbinæ ¼å¼çš„æ–‡ä»¶
    æ ¼å¼: [nvecs: int32, dim: int32, data: float32[nvecs*dim]]
    """
    with open(filename, 'rb') as f:
        nvecs = struct.unpack('i', f.read(4))[0]
        dim = struct.unpack('i', f.read(4))[0]
        
        if chunk_size is None:
            # è¯»å–æ•´ä¸ªæ–‡ä»¶
            data = np.fromfile(f, dtype=np.float32, count=nvecs*dim)
            data = data.reshape(nvecs, dim)
            return data
        else:
            # è¯»å–æŒ‡å®šå—
            end_idx = min(start_idx + chunk_size, nvecs)
            num_vectors_in_chunk = end_idx - start_idx
            offset = start_idx * dim * 4  # æ¯ä¸ªfloat32å 4å­—èŠ‚
            f.seek(offset, os.SEEK_CUR)
            data = np.fromfile(f, dtype=np.float32, count=num_vectors_in_chunk*dim)
            data = data.reshape(num_vectors_in_chunk, dim)
            return data, nvecs, dim

def read_ivecs(filename):
    """
    (æ­¤å‡½æ•°åœ¨æ­¤è„šæœ¬ä¸­æœªç”¨äºæ‰¹é‡è¯»å–ï¼Œä»…ä½œä¸ºå·¥å…·å‡½æ•°ä¿ç•™)
    è¯»å–.ivecsæ ¼å¼çš„äºŒè¿›åˆ¶æ–‡ä»¶ (ä¾‹å¦‚SIFT1Mçš„groundtruth)
    æ ¼å¼: å‘é‡å¾ªç¯ [dim: int32, data: int32[dim]]
    """
    a = np.fromfile(filename, dtype='int32')
    d = a[0]
    return a.reshape(-1, d + 1)[:, 1:].copy()

# ==============================================================================
# 2. è®¾ç½®å‚æ•°ä¸ç¯å¢ƒ
# ==============================================================================

# ä»è®­ç»ƒæ–‡ä»¶ä¸­è·å–ç»´åº¦ä¿¡æ¯
_, nt, d_train = read_fbin(LEARN_FILE, chunk_size=1)  # åªè¯»å–å…ƒæ•°æ®

# è·å–æ•°æ®é›†å¤§å°ä¿¡æ¯
_, nb, d_base = read_fbin(BASE_FILE, chunk_size=1)
_, nq, d_query = read_fbin(QUERY_FILE, chunk_size=1)

# éªŒè¯ç»´åº¦ä¸€è‡´æ€§
if d_train != d_base or d_train != d_query:
    raise ValueError(f"ç»´åº¦ä¸ä¸€è‡´: è®­ç»ƒé›†{d_train}ç»´, åŸºç¡€é›†{d_base}ç»´, æŸ¥è¯¢é›†{d_query}ç»´")

# è®¾ç½®å…¶ä»–å‚æ•°
cell_size = 256
nlist = nb // cell_size
nprobe = 32
chunk_size = 100000  # æ¯æ¬¡å¤„ç†çš„æ•°æ®å—å¤§å°
k = 10  # æŸ¥æ‰¾æœ€è¿‘çš„10ä¸ªé‚»å±…

M = 32  # HNSWçš„è¿æ¥æ•°
efconstruction = 40 # é»˜è®¤40
efsearch = 16       # é»˜è®¤16

# ==============================================================================
# ã€é‡æ„ç‚¹ã€‘: åœ¨ç´¢å¼•æ–‡ä»¶åä¸­åŒæ—¶ä½“ç° M å’Œ efConstruction çš„å€¼
# ==============================================================================
base_name = os.path.splitext(os.path.basename(BASE_FILE))[0]
# æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
clean_base_name = re.sub(r'[^a-zA-Z0-9_]', '_', base_name)
# åœ¨æ–‡ä»¶åä¸­æ·»åŠ  M å’Œ efc å‚æ•°ï¼Œä»¥åŒºåˆ†ä¸åŒå‚æ•°æ„å»ºçš„ç´¢å¼•
INDEX_FILE = os.path.join(DATA_DIR, f"{clean_base_name}_d{d_train}_nlist{nlist}_HNSWM{M}_efc{efconstruction}_IVFFlat.index")
# ==============================================================================

print("="*60)
print("Phase 0: ç¯å¢ƒè®¾ç½®")
print(f"å‘é‡ç»´åº¦ (d): {d_train}")
print(f"åŸºç¡€é›†å¤§å° (nb): {nb}, è®­ç»ƒé›†å¤§å° (ntrain): {nt}")
print(f"æŸ¥è¯¢é›†å¤§å° (nq): {nq}, åˆ†å—å¤§å° (chunk_size): {chunk_size}")
print(f"HNSW M (æ„å»ºå‚æ•°): {M}")
print(f"HNSW efConstruction (æ„å»ºå‚æ•°): {efconstruction}")
print(f"ç´¢å¼•å°†ä¿å­˜åœ¨ç£ç›˜æ–‡ä»¶: {INDEX_FILE}")
print(f"IVFç»Ÿè®¡åŠŸèƒ½: {'å¯ç”¨' if ENABLE_IVF_STATS else 'ç¦ç”¨'}")
print(f"æœç´¢åˆ†åŒºç»Ÿè®¡åŠŸèƒ½: {'å¯ç”¨' if ENABLE_SEARCH_PARTITION_STATS else 'ç¦ç”¨'}")
print(f"è¯¦ç»†å†…å­˜ç›‘æ§: {'å¯ç”¨' if ENABLE_DETAILED_MEMORY_MONITORING else 'ç¦ç”¨'}")
print(f"å†…å­˜å¯è§†åŒ–: {'å¯ç”¨' if ENABLE_MEMORY_VISUALIZATION else 'ç¦ç”¨'}")
print("="*60)

# è®°å½•åˆå§‹å†…å­˜çŠ¶æ€
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("ç¨‹åºå¼€å§‹")

# ==============================================================================
# 3. æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
# ==============================================================================
if os.path.exists(INDEX_FILE):
    print(f"ç´¢å¼•æ–‡ä»¶ {INDEX_FILE} å·²å­˜åœ¨ï¼Œè·³è¿‡ç´¢å¼•æ„å»ºé˜¶æ®µ")
    skip_index_building = True
else:
    print("ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†æ„å»ºæ–°ç´¢å¼•")
    skip_index_building = False

# ==============================================================================
# 4. è®­ç»ƒé‡åŒ–å™¨ 
# ==============================================================================
if not skip_index_building:
    if ENABLE_DETAILED_MEMORY_MONITORING:
        with memory_monitor.monitor_phase("è®­ç»ƒHNSWç²—é‡åŒ–å™¨"):
            print("\nPhase 1: è®­ç»ƒ HNSW ç²—é‡åŒ–å™¨ (in-memory)")
            coarse_quantizer = faiss.IndexHNSWFlat(d_train, M, faiss.METRIC_L2)
            coarse_quantizer.hnsw.efConstruction = efconstruction
            coarse_quantizer.hnsw.efSearch = efsearch
            print(f"efconstruction: {coarse_quantizer.hnsw.efConstruction}, efSearch: {coarse_quantizer.hnsw.efSearch}")
            # coarse_quantizer = faiss.IndexFlatL2(d_train)
            index_for_training = faiss.IndexIVFFlat(coarse_quantizer, d_train, nlist, faiss.METRIC_L2)
            index_for_training.verbose = True

            xt = read_fbin(LEARN_FILE)

            print("è®­ç»ƒèšç±»ä¸­å¿ƒå¹¶æ„å»º HNSW é‡åŒ–å™¨...")
            start_time = time.time()
            index_for_training.train(xt)
            end_time = time.time()

            print(f"é‡åŒ–å™¨è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
            print(f"ç²—é‡åŒ–å™¨ä¸­çš„è´¨å¿ƒæ•°é‡: {coarse_quantizer.ntotal}")
            del xt
            del index_for_training
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            memory_monitor.force_gc_and_log("è®­ç»ƒå®Œæˆå")
    else:
        print("\nPhase 1: è®­ç»ƒ HNSW ç²—é‡åŒ–å™¨ (in-memory)")
        coarse_quantizer = faiss.IndexHNSWFlat(d_train, M, faiss.METRIC_L2)
        coarse_quantizer.hnsw.efConstruction = efconstruction
        coarse_quantizer.hnsw.efSearch = efsearch
        print(f"efconstruction: {coarse_quantizer.hnsw.efConstruction}, efSearch: {coarse_quantizer.hnsw.efSearch}")
        # coarse_quantizer = faiss.IndexFlatL2(d_train)
        index_for_training = faiss.IndexIVFFlat(coarse_quantizer, d_train, nlist, faiss.METRIC_L2)
        index_for_training.verbose = True

        xt = read_fbin(LEARN_FILE)

        print("è®­ç»ƒèšç±»ä¸­å¿ƒå¹¶æ„å»º HNSW é‡åŒ–å™¨...")
        start_time = time.time()
        index_for_training.train(xt)
        end_time = time.time()

        print(f"é‡åŒ–å™¨è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"ç²—é‡åŒ–å™¨ä¸­çš„è´¨å¿ƒæ•°é‡: {coarse_quantizer.ntotal}")
        del xt
        del index_for_training

    # ==============================================================================
    # 5. åˆ›å»ºä¸€ä¸ªç©ºçš„ã€åŸºäºç£ç›˜çš„ç´¢å¼•æ¡†æ¶
    # ==============================================================================
    print("\nPhase 2: åˆ›å»ºç©ºçš„ç£ç›˜ç´¢å¼•æ¡†æ¶")
    index_shell = faiss.IndexIVFFlat(coarse_quantizer, d_train, nlist, faiss.METRIC_L2)
    print(f"å°†ç©ºçš„ç´¢å¼•æ¡†æ¶å†™å…¥ç£ç›˜: {INDEX_FILE}")
    faiss.write_index(index_shell, INDEX_FILE)
    del index_shell

    # ==============================================================================
    # 6. åˆ†å—å‘ç£ç›˜ç´¢å¼•ä¸­æ·»åŠ æ•°æ® (ä»base.fbin)
    # ==============================================================================
    if ENABLE_DETAILED_MEMORY_MONITORING:
        with memory_monitor.monitor_phase("åˆ†å—æ·»åŠ æ•°æ®åˆ°ç£ç›˜ç´¢å¼•"):
            print("\nPhase 3: åˆ†å—æ·»åŠ æ•°æ®åˆ°ç£ç›˜ç´¢å¼•")

            # å…¼å®¹ä¸åŒFaissç‰ˆæœ¬çš„IOæ ‡å¿—å¤„ç†
            try:
                IO_FLAG_READ_WRITE = faiss.IO_FLAG_READ_WRITE
            except AttributeError:
                try:
                    IO_FLAG_READ_WRITE = faiss.index_io.IO_FLAG_READ_WRITE
                except AttributeError:
                    IO_FLAG_READ_WRITE = 0

            print(f"ä½¿ç”¨IOæ ‡å¿—: {IO_FLAG_READ_WRITE} (è¯»å†™æ¨¡å¼)")

            index_ondisk = faiss.read_index(INDEX_FILE, IO_FLAG_READ_WRITE)
            start_time = time.time()

            num_chunks = (nb + chunk_size - 1) // chunk_size
            for i in range(0, nb, chunk_size):
                chunk_idx = i // chunk_size + 1
                print(f"       -> æ­£åœ¨å¤„ç†å— {chunk_idx}/{num_chunks}: å‘é‡ {i} åˆ° {min(i+chunk_size, nb)-1}")
                
                # ä»base.fbinä¸­è¯»å–æ•°æ®å—
                xb_chunk, _, _ = read_fbin(BASE_FILE, i, chunk_size)
                
                index_ondisk.add(xb_chunk)
                del xb_chunk
                
                # æ›´é¢‘ç¹çš„å†…å­˜ç›‘æ§ - æ¯å¤„ç†5ä¸ªå—è¿›è¡Œä¸€æ¬¡è®°å½•
                if chunk_idx % 5 == 0:
                    memory_monitor.log_memory_snapshot(f"å¤„ç†å—{chunk_idx}")
                
                # åœ¨å¤„ç†å¤§å—æ—¶ï¼Œæ¯ä¸ªå—éƒ½è¿›è¡Œç›‘æ§
                if chunk_size >= 50000:  # å¦‚æœå—å¾ˆå¤§ï¼Œæ¯ä¸ªå—éƒ½è®°å½•
                    memory_monitor.log_memory_snapshot(f"å®Œæˆå—{chunk_idx}")

            print(f"\næ‰€æœ‰æ•°æ®å—æ·»åŠ å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
            print(f"ç£ç›˜ç´¢å¼•ä¸­çš„å‘é‡æ€»æ•° (ntotal): {index_ondisk.ntotal}")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            memory_monitor.force_gc_and_log("åˆ†å—æ·»åŠ å®Œæˆå")
    else:
        print("\nPhase 3: åˆ†å—æ·»åŠ æ•°æ®åˆ°ç£ç›˜ç´¢å¼•")

        # å…¼å®¹ä¸åŒFaissç‰ˆæœ¬çš„IOæ ‡å¿—å¤„ç†
        try:
            IO_FLAG_READ_WRITE = faiss.IO_FLAG_READ_WRITE
        except AttributeError:
            try:
                IO_FLAG_READ_WRITE = faiss.index_io.IO_FLAG_READ_WRITE
            except AttributeError:
                IO_FLAG_READ_WRITE = 0

        print(f"ä½¿ç”¨IOæ ‡å¿—: {IO_FLAG_READ_WRITE} (è¯»å†™æ¨¡å¼)")

        index_ondisk = faiss.read_index(INDEX_FILE, IO_FLAG_READ_WRITE)
        start_time = time.time()

        num_chunks = (nb + chunk_size - 1) // chunk_size
        for i in range(0, nb, chunk_size):
            chunk_idx = i // chunk_size + 1
            print(f"       -> æ­£åœ¨å¤„ç†å— {chunk_idx}/{num_chunks}: å‘é‡ {i} åˆ° {min(i+chunk_size, nb)-1}")
            
            # ä»base.fbinä¸­è¯»å–æ•°æ®å—
            xb_chunk, _, _ = read_fbin(BASE_FILE, i, chunk_size)
            
            index_ondisk.add(xb_chunk)
            del xb_chunk

        print(f"\næ‰€æœ‰æ•°æ®å—æ·»åŠ å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’")
        print(f"ç£ç›˜ç´¢å¼•ä¸­çš„å‘é‡æ€»æ•° (ntotal): {index_ondisk.ntotal}")
    
    # ===========================================================
    # 7. æ–°å¢: è¾“å‡ºIVFåˆ†åŒºç»Ÿè®¡ä¿¡æ¯ (ä»…åœ¨æ„å»ºç´¢å¼•æ—¶æ‰§è¡Œ)
    # ===========================================================
    if ENABLE_IVF_STATS and not skip_index_building:
        print("\nè¾“å‡ºIVFåˆ†åŒºç»Ÿè®¡ä¿¡æ¯...")
        start_stats_time = time.time()
        
        # è·å–å€’æ’åˆ—è¡¨
        invlists = index_ondisk.invlists
        
        # å‡†å¤‡ç»Ÿè®¡ä¿¡æ¯
        partition_stats = []
        non_empty_partitions = 0
        max_size = 0
        min_size = float('inf')
        total_vectors = 0
        
        # éå†æ‰€æœ‰åˆ†åŒº
        for list_id in range(nlist):
            list_size = invlists.list_size(list_id)
            
            # ä¿®æ”¹ç‚¹ 1ï¼šæ— è®ºåˆ†åŒºå¤§å°æ˜¯å¦ä¸º0ï¼Œéƒ½è®°å½•ä¸‹æ¥ï¼Œä»¥ä¾¿ç”Ÿæˆå®Œæ•´çš„CSVæŠ¥å‘Š
            partition_stats.append((list_id, list_size))
            
            # ä»…é’ˆå¯¹éç©ºåˆ†åŒºæ›´æ–°æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯
            if list_size > 0:
                non_empty_partitions += 1
                max_size = max(max_size, list_size)
                min_size = min(min_size, list_size)
                total_vectors += list_size
                
        # ä¿®æ”¹ç‚¹ 2ï¼šå¤„ç†æ²¡æœ‰éç©ºåˆ†åŒºçš„è¾¹ç¼˜æƒ…å†µï¼Œé¿å…æ‰“å° 'inf'
        if non_empty_partitions == 0:
            min_size = 0
        
        # è®¡ç®—éç©ºåˆ†åŒºçš„å¹³å‡å¤§å° (total_vectors æ˜¯éç©ºåˆ†åŒºä¸­çš„å‘é‡æ€»æ•°)
        avg_size = total_vectors / non_empty_partitions if non_empty_partitions > 0 else 0
        
        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        print(f"IVFåˆ†åŒºç»Ÿè®¡æ‘˜è¦:")
        print(f"  åˆ†åŒºæ€»æ•°: {nlist}")
        print(f"  éç©ºåˆ†åŒºæ•°: {non_empty_partitions} ({non_empty_partitions/nlist*100:.2f}%)")
        print(f"  æœ€å¤§åˆ†åŒºå¤§å°: {max_size}")
        # ä¿®æ”¹ç‚¹ 3ï¼šä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæ˜ç¡®æŒ‡å‡ºè¿™æ˜¯éç©ºåˆ†åŒºçš„æœ€å°å€¼
        print(f"  æœ€å°(éç©º)åˆ†åŒºå¤§å°: {min_size}")
        # ä¿®æ”¹ç‚¹ 3ï¼šä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæ˜ç¡®æŒ‡å‡ºè¿™æ˜¯éç©ºåˆ†åŒºçš„å¹³å‡å€¼
        print(f"  å¹³å‡(éç©º)åˆ†åŒºå¤§å°: {avg_size:.2f}")
        
        # å°†è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯å†™å…¥æ–‡ä»¶
        # æ­¤éƒ¨åˆ†æ— éœ€ä¿®æ”¹ï¼Œå› ä¸ºå®ƒç°åœ¨ä¼šæ­£ç¡®å¤„ç†åŒ…å«æ‰€æœ‰åˆ†åŒºçš„ partition_stats åˆ—è¡¨
        stats_filename = os.path.splitext(INDEX_FILE)[0] + "_ivf_stats.csv"
        with open(stats_filename, 'w') as f:
            f.write("partition_id,vector_count\n")
            for list_id, size in partition_stats:
                f.write(f"{list_id},{size}\n")
                
        print(f"åˆ†åŒºç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_filename}")
        print(f"ç»Ÿè®¡è€—æ—¶: {time.time() - start_stats_time:.2f}ç§’")
    
    # ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜
    print(f"æ­£åœ¨å°†æœ€ç»ˆç´¢å¼•å†™å›ç£ç›˜: {INDEX_FILE}")
    faiss.write_index(index_ondisk, INDEX_FILE)
    del index_ondisk

# ==============================================================================
# 8. ä½¿ç”¨å†…å­˜æ˜ å°„ (mmap) è¿›è¡Œæœç´¢ (ä½¿ç”¨query.fbin)
# ==============================================================================
print("\nPhase 4: ä½¿ç”¨å†…å­˜æ˜ å°„æ¨¡å¼è¿›è¡Œæœç´¢")
print(f"ä»¥ mmap æ¨¡å¼æ‰“å¼€ç£ç›˜ç´¢å¼•: {INDEX_FILE}")

# åœ¨ç´¢å¼•åŠ è½½å‰è®¾ç½®åŸºçº¿å’Œæ–‡ä»¶è·¯å¾„
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("ç´¢å¼•åŠ è½½å‰")
    # è®¾ç½®ç´¢å¼•æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºmmapæ£€æµ‹
    memory_monitor.set_index_file_path(INDEX_FILE)
    # è·å–ç´¢å¼•åŠ è½½å‰çš„å†…å­˜çŠ¶æ€ä½œä¸ºåŸºçº¿
    baseline_memory_info = memory_monitor.get_memory_info()
    memory_monitor.set_index_memory_baseline(baseline_memory_info['rss_mb'])

# å…¼å®¹ä¸åŒFaissç‰ˆæœ¬çš„IOæ ‡å¿—å¤„ç†
try:
    IO_FLAG_MMAP = faiss.IO_FLAG_MMAP
except AttributeError:
    try:
        IO_FLAG_MMAP = faiss.index_io.IO_FLAG_MMAP
    except AttributeError:
        IO_FLAG_MMAP = 4

print(f"ä½¿ç”¨IOæ ‡å¿—: {IO_FLAG_MMAP} (å†…å­˜æ˜ å°„æ¨¡å¼)")

index_final = faiss.read_index(INDEX_FILE, IO_FLAG_MMAP)
index_final.nprobe = nprobe
# index_final.quantizer.hnsw.efSearch = 100  # è®¾ç½®HNSWçš„efSearchå‚æ•°ä»¥åŒ¹é…nprobe
faiss.omp_set_num_threads(40)
index_final.parallel_mode = 0
print(f"å¹¶è¡Œæ¨¡å¼çº¿ç¨‹æ•°: {faiss.omp_get_max_threads()}")
print(f"å¹¶è¡Œæ¨¡å¼: {index_final.parallel_mode}")
print(f"ç´¢å¼•å·²å‡†å¤‡å¥½æœç´¢ (nprobe={index_final.nprobe})")
generic_quantizer = index_final.quantizer
quantizer_hnsw = faiss.downcast_index(generic_quantizer)
quantizer_hnsw.hnsw.efSearch = efsearch
print(f"efConstruction: {quantizer_hnsw.hnsw.efConstruction}, efSearch: {quantizer_hnsw.hnsw.efSearch}")

# ç´¢å¼•åŠ è½½å®Œæˆåè®°å½•å†…å­˜çŠ¶æ€
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("ç´¢å¼•åŠ è½½å®Œæˆ")

print("ä» query.fbin åŠ è½½æŸ¥è¯¢å‘é‡...")
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.set_current_phase("åŠ è½½æŸ¥è¯¢æ•°æ®")
    memory_monitor.log_memory_snapshot("æŸ¥è¯¢å‘é‡åŠ è½½å¼€å§‹")

xq = read_fbin(QUERY_FILE)

if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.log_memory_snapshot("æŸ¥è¯¢å‘é‡åŠ è½½å®Œæˆ")

# åœ¨æœç´¢å‰è¿›è¡Œå†…å­˜ä¼˜åŒ–
if ENABLE_DETAILED_MEMORY_MONITORING:
    memory_monitor.set_current_phase("æœç´¢å‡†å¤‡")
    memory_monitor.force_gc_and_log("æœç´¢å‰ä¼˜åŒ–")

# ==============================================================================
# 8.5. æ–°å¢: ç»Ÿè®¡å¹¶ä¿å­˜æ¯ä¸ªæŸ¥è¯¢å‘½ä¸­çš„åˆ†åŒºç‚¹æ•°å æ€»ç‚¹æ•°çš„æ¯”ä¾‹
# ==============================================================================
if ENABLE_SEARCH_PARTITION_STATS:
    print("\n" + "="*60)
    print(f"Phase 4.5: ç»Ÿè®¡æœç´¢åˆ†åŒºä¿¡æ¯ (nprobe={nprobe})")
    
    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦ä¸ºIVFç±»å‹ï¼Œå› ä¸ºè¯¥é€»è¾‘ä¾èµ–äºquantizerå’Œinvlists
    if not isinstance(index_final, faiss.IndexIVF):
        print("é”™è¯¯ï¼šç´¢å¼•ç±»å‹ä¸æ˜¯IndexIVFï¼Œæ— æ³•æ‰§è¡Œåˆ†åŒºç»Ÿè®¡ã€‚")
    else:
        total_vectors_in_index = index_final.ntotal
        print(f"ç´¢å¼•ä¸­çš„æ€»å‘é‡æ•°: {total_vectors_in_index}")
        
        if total_vectors_in_index == 0:
            print("è­¦å‘Šï¼šç´¢å¼•ä¸­æ²¡æœ‰å‘é‡ï¼Œæ‰€æœ‰æ¯”ä¾‹å°†ä¸º0ã€‚")
        
        print("æ­£åœ¨ä¸ºæ¯ä¸ªæŸ¥è¯¢å‘é‡æŸ¥æ‰¾å¯¹åº”çš„åˆ†åŒº...")
        # 1. å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡ï¼Œç”¨ç²—é‡åŒ–å™¨æ‰¾åˆ°nprobeä¸ªæœ€è¿‘çš„ç°‡å¿ƒ(åˆ†åŒº)
        # I_quant çš„ç»´åº¦æ˜¯ (nq, nprobe)ï¼Œå­˜å‚¨äº†æ¯ä¸ªæŸ¥è¯¢å‘½ä¸­çš„åˆ†åŒºID
        _ , I_quant = index_final.quantizer.search(xq, nprobe)
        
        ratios = []
        print(f"æ­£åœ¨è®¡ç®— {nq} ä¸ªæŸ¥è¯¢çš„å‘½ä¸­åˆ†åŒºç‚¹æ•°æ¯”ä¾‹...")
        
        # 2. éå†æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœ
        for i in range(nq):
            probed_list_ids = I_quant[i]
            
            # 3. ç´¯åŠ è¿™äº›åˆ†åŒºä¸­çš„å‘é‡æ€»æ•°
            num_vectors_in_probed_partitions = 0
            for list_id in probed_list_ids:
                if list_id >= 0: # æœ‰æ•ˆçš„åˆ†åŒºID
                    num_vectors_in_probed_partitions += index_final.invlists.list_size(int(list_id))
            
            # 4. è®¡ç®—æ¯”ä¾‹
            ratio = num_vectors_in_probed_partitions / total_vectors_in_index if total_vectors_in_index > 0 else 0
            ratios.append(ratio)

        # 5. å°†ç»“æœå†™å…¥æ–‡ä»¶
        try:
            with open(SEARCH_STATS_FILENAME, 'w') as f:
                for ratio in ratios:
                    f.write(f"{ratio:.8f}\n") # å†™å…¥æ—¶ä¿ç•™8ä½å°æ•°
            print(f"æœç´¢åˆ†åŒºç»Ÿè®¡æ¯”ä¾‹å·²æˆåŠŸå†™å…¥æ–‡ä»¶: {SEARCH_STATS_FILENAME}")
        except IOError as e:
            print(f"é”™è¯¯ï¼šæ— æ³•å†™å…¥ç»Ÿè®¡æ–‡ä»¶ {SEARCH_STATS_FILENAME}ã€‚åŸå› : {e}")
            
    print("="*60)


if ENABLE_DETAILED_MEMORY_MONITORING:
    with memory_monitor.monitor_phase("æ‰§è¡Œæœç´¢"):
        print("\næ‰§è¡Œæœç´¢...")
        memory_monitor.log_memory_snapshot("æœç´¢å¼€å§‹")
        start_time = time.time()
        
        # å¦‚æœæŸ¥è¯¢æ•°é‡å¾ˆå¤§ï¼Œåˆ†æ‰¹è¿›è¡Œæœç´¢å¹¶ç›‘æ§
        if nq > 1000:
            batch_size = 500
            D_batches = []
            I_batches = []
            
            for batch_start in range(0, nq, batch_size):
                batch_end = min(batch_start + batch_size, nq)
                xq_batch = xq[batch_start:batch_end]
                
                memory_monitor.log_memory_snapshot(f"æœç´¢æ‰¹æ¬¡{batch_start//batch_size + 1}")
                D_batch, I_batch = index_final.search(xq_batch, k)
                
                D_batches.append(D_batch)
                I_batches.append(I_batch)
            
            D = np.vstack(D_batches)
            I = np.vstack(I_batches)
        else:
            D, I = index_final.search(xq, k)
        
        end_time = time.time()
        memory_monitor.log_memory_snapshot("æœç´¢å®Œæˆ")
else:
    print("\næ‰§è¡Œæœç´¢...")
    start_time = time.time()
    D, I = index_final.search(xq, k)
    end_time = time.time()

# ä» .indexIVF_stats å±æ€§ä¸­è·å–ç»Ÿè®¡å¯¹è±¡
stats = faiss.cvar.indexIVF_stats

print("\n========== æœç´¢æ€§èƒ½ç»Ÿè®¡ ==========")
print(f"æŸ¥è¯¢å‘é‡æ€»æ•° (nq): {stats.nq}")
print(f"æ€»æœç´¢æ—¶é—´ (search_time): {stats.search_time:.3f} ms")
print(f"  - ç²—ç­›é˜¶æ®µç”¨æ—¶ (quantization_time): {stats.quantization_time:.3f} ms")
# ç²¾ç­›æ—¶é—´å¯ä»¥é€šè¿‡æ€»æ—¶é—´å‡å»ç²—ç­›æ—¶é—´å¾—åˆ°
print(f"  - ç²¾ç­›é˜¶æ®µç”¨æ—¶ (search_time - quantization_time): {stats.search_time - stats.quantization_time:.3f} ms")
print("-" * 30)
print(f"è®¿é—®çš„å€’æ’åˆ—è¡¨æ€»æ•° (nlist): {stats.nlist}")
print(f"è®¡ç®—çš„å‘é‡è·ç¦»æ€»æ•° (ndis): {stats.ndis}")
print(f"ç»“æœå †çš„æ›´æ–°æ€»æ¬¡æ•° (nheap_updates): {stats.nheap_updates}")
print("====================================\n")

# --- æ–°å¢QPSè®¡ç®— ---
search_duration = end_time - start_time
print(f"æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_duration:.2f} ç§’")

if search_duration > 0:
    qps = nq / search_duration
    print(f"QPS (æ¯ç§’æŸ¥è¯¢ç‡): {qps:.2f}")
else:
    print("æœç´¢è€—æ—¶è¿‡çŸ­ï¼Œæ— æ³•è®¡ç®—QPS")
# --- QPSè®¡ç®—ç»“æŸ ---


# ==============================================================================
# 9.  æ–°å¢: æ ¹æ®Groundtruthè®¡ç®—å¬å›ç‡ (å†…å­˜ä¼˜åŒ–ç‰ˆ)
# ==============================================================================
print("\n" + "="*60)
print("Phase 5: è®¡ç®—å¬å›ç‡ (å†…å­˜ä¼˜åŒ–ç‰ˆ)")

if not os.path.exists(GROUNDTRUTH_FILE):
    print(f"Groundtruthæ–‡ä»¶æœªæ‰¾åˆ°: {GROUNDTRUTH_FILE}")
    print("è·³è¿‡å¬å›ç‡è®¡ç®—ã€‚")
else:
    print(f"ä»¥æµå¼æ–¹å¼ä» {GROUNDTRUTH_FILE} è¯»å– groundtruth æ•°æ®è¿›è¡Œè®¡ç®—...")
    
    total_found = 0
    
    # ä½¿ç”¨withè¯­å¥ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å…³é—­
    with open(GROUNDTRUTH_FILE, 'rb') as f:
        # é¦–å…ˆï¼Œä»æ–‡ä»¶çš„ç¬¬ä¸€ä¸ªæ•´æ•°ç¡®å®šgroundtruthçš„ç»´åº¦ (k_gt)
        dim_bytes = f.read(4)
        if not dim_bytes:
            raise EOFError("Groundtruth æ–‡ä»¶ä¸ºç©ºæˆ–å·²æŸåã€‚")
        k_gt = struct.unpack('i', dim_bytes)[0]
        
        print(f"Groundtruth ç»´åº¦ (k_gt): {k_gt}")
        
        # è®¡ç®—æ–‡ä»¶ä¸­æ¯æ¡è®°å½•çš„å­—èŠ‚å¤§å°
        # æ¯æ¡è®°å½•åŒ…å«1ä¸ªç»´åº¦æ•´æ•°å’Œk_gtä¸ªIDæ•´æ•°ï¼Œæ¯ä¸ªæ•´æ•°4å­—èŠ‚
        record_size_bytes = (k_gt + 1) * 4
        
        # éªŒè¯æ–‡ä»¶ä¸­çš„å‘é‡æ•°é‡æ˜¯å¦ä¸æŸ¥è¯¢æ•°é‡(nq)åŒ¹é…
        f.seek(0, os.SEEK_END)
        total_file_size = f.tell()
        num_gt_vectors = total_file_size // record_size_bytes
        if nq != num_gt_vectors:
              print(f"è­¦å‘Š: æŸ¥è¯¢æ•°é‡({nq})ä¸groundtruthä¸­çš„æ•°é‡({num_gt_vectors})ä¸åŒ¹é…!")

        print(f"æ­£åœ¨è®¡ç®— Recall@{k}...")
        
        # éå†æ¯ä¸ªæŸ¥è¯¢ç»“æœ
        for i in range(nq):
            # è®¡ç®—ç¬¬ i æ¡è®°å½•åœ¨æ–‡ä»¶ä¸­çš„èµ·å§‹ä½ç½®
            offset = i * record_size_bytes
            f.seek(offset)
            
            # ä»è¯¥ä½ç½®è¯»å–ä¸€æ¡å®Œæ•´çš„è®°å½• (k_gt + 1 ä¸ªæ•´æ•°)
            record_data = np.fromfile(f, dtype=np.int32, count=k_gt + 1)
            
            # è®°å½•ä¸­çš„ç¬¬ä¸€ä¸ªæ•´æ•°æ˜¯ç»´åº¦ï¼Œæˆ‘ä»¬æå–ä»ç¬¬äºŒä¸ªå…ƒç´ å¼€å§‹çš„IDåˆ—è¡¨
            gt_i = record_data[1:]
            
            found_count = np.isin(I[i], gt_i[:k]).sum()
            total_found += found_count
            
    # å¬å›ç‡ = (æ‰€æœ‰æŸ¥è¯¢æ‰¾åˆ°çš„æ­£ç¡®è¿‘é‚»æ€»æ•°) / (æ‰€æœ‰æŸ¥è¯¢è¿”å›çš„ç»“æœæ€»æ•°)
    recall = total_found / (nq * k)
    
    print(f"\næŸ¥è¯¢äº† {nq} ä¸ªå‘é‡, k={k}")
    print(f"åœ¨top-{k}çš„ç»“æœä¸­ï¼Œæ€»å…±æ‰¾åˆ°äº† {total_found} ä¸ªçœŸå®çš„è¿‘é‚»ã€‚")
    print(f"Recall@{k}: {recall:.4f}")

print("="*60)


# ==============================================================================
# 10. æŠ¥å‘Šå³°å€¼å†…å­˜
# ==============================================================================
print("\n" + "="*60)
print("å†…å­˜ä½¿ç”¨æƒ…å†µæŠ¥å‘Š")
print("="*60)

# ä¼ ç»Ÿæ–¹æ³•ï¼ˆresource.getrusageï¼‰
if platform.system() in ["Linux", "Darwin"]:
    peak_memory_bytes = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    if platform.system() == "Linux":
        peak_memory_bytes *= 1024
    peak_memory_mb = peak_memory_bytes / (1024 * 1024)
    print(f"ä¼ ç»Ÿæ–¹æ³• - æ•´ä¸ªç¨‹åºè¿è¡ŒæœŸé—´çš„å³°å€¼å†…å­˜å ç”¨: {peak_memory_mb:.2f} MB")

# æ–°çš„è¯¦ç»†å†…å­˜åˆ†æ
if ENABLE_DETAILED_MEMORY_MONITORING:
    print("\nè¯¦ç»†å†…å­˜åˆ†æ:")
    summary = memory_monitor.get_memory_summary()
    if summary:
        print(f"  å³°å€¼RSSå†…å­˜: {summary['peak_rss_mb']:.2f} MB")
        print(f"  å¹³å‡RSSå†…å­˜: {summary['avg_rss_mb']:.2f} MB")
        print(f"  æ€»ç›‘æ§å¿«ç…§æ•°: {summary['total_snapshots']}")
    
    # å†…å­˜å¢é•¿æ¨¡å¼åˆ†æ
    print("\nå†…å­˜å¢é•¿æ¨¡å¼åˆ†æ:")
    growth_analysis = memory_monitor.analyze_memory_growth_pattern()
    if growth_analysis:
        print(f"  æ€»å†…å­˜å¢é•¿: {growth_analysis['total_growth_mb']:.2f} MB")
        print(f"  å³°å€¼ä½¿ç”¨: {growth_analysis['peak_usage_mb']:.2f} MB")
        print("  å„é˜¶æ®µå†…å­˜å¢é•¿:")
        for phase_info in growth_analysis['growth_phases']:
            print(f"    {phase_info['phase']}: +{phase_info['growth_mb']:.2f} MB (æ€»è®¡: {phase_info['rss_mb']:.2f} MB)")
    
    # å†…å­˜åˆ†è§£åˆ†æï¼ˆåŸºäºå¤šç§æ£€æµ‹æ–¹æ³•ï¼‰
    print("\nå†…å­˜ä½¿ç”¨åˆ†è§£:")
    final_info = memory_monitor.get_memory_info()
    if final_info['rss_mb'] > 0:
        index_percentage = final_info['index_memory_mb']/final_info['rss_mb']*100
        other_percentage = final_info['other_memory_mb']/final_info['rss_mb']*100
        print(f"  ç´¢å¼•å†…å­˜: {final_info['index_memory_mb']:.2f} MB ({index_percentage:.1f}%)")
        print(f"  å…¶ä»–å†…å­˜: {final_info['other_memory_mb']:.2f} MB ({other_percentage:.1f}%)")
        
        # æ˜¾ç¤ºmmapæ£€æµ‹è¯¦ç»†ä¿¡æ¯
        if 'mmap_detection' in final_info:
            mmap_info = final_info['mmap_detection']
            print(f"\n  mmapæ£€æµ‹è¯¦æƒ…:")
            print(f"    æ–¹æ³•: {mmap_info.get('method', 'unknown')}")
            print(f"    æ£€æµ‹åˆ°çš„ç´¢å¼•å†…å­˜: {mmap_info.get('index_memory_mb', 0):.2f} MB")
            if 'mmap_count' in mmap_info:
                print(f"    å†…å­˜æ˜ å°„æ•°é‡: {mmap_info['mmap_count']}")
        
        if 'smaps_detection' in final_info:
            smaps_info = final_info['smaps_detection']
            print(f"\n  smapsæ£€æµ‹è¯¦æƒ…:")
            print(f"    æ–¹æ³•: {smaps_info.get('method', 'unknown')}")
            print(f"    æ£€æµ‹åˆ°çš„ç´¢å¼•å†…å­˜: {smaps_info.get('index_memory_mb', 0):.2f} MB")
            if 'mmap_entries' in smaps_info:
                print(f"    æ˜ å°„æ¡ç›®æ•°é‡: {smaps_info['mmap_entries']}")
    else:
        print("  æ— æ³•è®¡ç®—å†…å­˜åˆ†è§£ï¼ˆRSSå†…å­˜ä¸º0ï¼‰")
    
    # æ˜¾ç¤ºtracemallocç»Ÿè®¡ä¿¡æ¯
    print("\nå†…å­˜ä½¿ç”¨çƒ­ç‚¹åˆ†æ:")
    memory_monitor.get_tracemalloc_top_stats(10)
    
    # æœ€ç»ˆå†…å­˜çŠ¶æ€
    print(f"\næœ€ç»ˆå†…å­˜çŠ¶æ€:")
    print(f"  RSSå†…å­˜: {final_info['rss_mb']:.2f} MB")
    print(f"  Pythonå¯¹è±¡æ•°: {final_info['python_objects']}")
    if 'traced_current_mb' in final_info:
        print(f"  Tracedå†…å­˜: {final_info['traced_current_mb']:.2f} MB")
    
    # å†…å­˜ä¼˜åŒ–å»ºè®®
    print("\nå†…å­˜ä¼˜åŒ–å»ºè®®:")
    suggestions = memory_monitor.get_memory_optimization_suggestions()
    if suggestions:
        for suggestion in suggestions:
            print(f"  {suggestion}")
    else:
        print("  âœ… å†…å­˜ä½¿ç”¨æƒ…å†µè‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")
    
    print(f"\nå†…å­˜æ—¥å¿—å·²ä¿å­˜åˆ°: {MEMORY_LOG_FILENAME}")
    
    # ç”Ÿæˆå†…å­˜å¯è§†åŒ–å›¾è¡¨
    if ENABLE_MEMORY_VISUALIZATION:
        print("\nç”Ÿæˆå†…å­˜ä½¿ç”¨å¯è§†åŒ–å›¾è¡¨...")
        memory_monitor.generate_memory_visualization(MEMORY_PLOT_FILENAME)
    
    # ç”Ÿæˆæœ€ç»ˆçš„å†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨
    if ENABLE_FINAL_MEMORY_PLOT:
        print("\nç”Ÿæˆæœ€ç»ˆå†…å­˜ä½¿ç”¨æƒ…å†µå›¾è¡¨...")
        memory_monitor.generate_final_memory_plot(FINAL_MEMORY_PLOT_FILENAME)
    
    # æ˜¾ç¤ºç›‘æ§ç»Ÿè®¡ä¿¡æ¯
    print("\nç›‘æ§ç»Ÿè®¡ä¿¡æ¯:")
    monitoring_stats = memory_monitor.get_monitoring_statistics()
    if monitoring_stats:
        print(f"  æ€»ç›‘æ§è®°å½•æ•°: {monitoring_stats['total_snapshots']}")
        print(f"  æ‰‹åŠ¨è®°å½•æ•°: {monitoring_stats['manual_snapshots']}")
        print(f"  å®šæ—¶é‡‡æ ·æ•°: {monitoring_stats['timed_snapshots']}")
        print(f"  å˜åŒ–è§¦å‘æ•°: {monitoring_stats['change_triggered_snapshots']}")
        print(f"  ç›‘æ§æ—¶é•¿: {monitoring_stats['monitoring_duration']:.1f}ç§’")
        print(f"  å¹³å‡é‡‡æ ·ç‡: {monitoring_stats['average_sampling_rate']:.2f}æ¬¡/ç§’")
    
    # æ¸…ç†èµ„æº
    memory_monitor.cleanup()
else:
    print("è¯¦ç»†å†…å­˜ç›‘æ§å·²ç¦ç”¨")

print("="*60)